---
title: "gym_members"
author: "Nuria Oviedo, Aitana Garcia y Marcos López"
date: "2025-02-06"
output: 
  html_document:
    html_document:
    toc: true
    toc_depth: 5
    toc_float: 
      smooth_scroll: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 0. Introducción

El conjunto de datos contiene un análisis de patrones de actividad física y rendimiento en distintos niveles de experiencia en gimnasios.

Estos datos se han extraído de [kaggle](https://www.kaggle.com/datasets/valakhorasani/gym-members-exercise-dataset). Según la propia descripción de los datos,este conjunto de datos nos proporciona una descripción detallada de las rutinas de ejercicio, los atributos físicos y las métricas de aptitud física de los miembros de gimnasios. En temas de salud es muy importante llevar un monitoreo de las cosas que hay que hacer para estar bien físicamente. El objetivo de este sistema es poder buscar patrones y evidencias de lo que tiene que hacer una persona para estar bien fisica y mentalmente. Este conjunto de dato nos da información sobre datos demográficos y niveles de experiencia, lo que permite un análisis integral de los patrones de aptitud física, la progresión de los atletas y las tendencias de salud. 

Según la descripción oficial de los datos, las variables que conforman el conjunto de datos son:

* Edad: Edad del miembro del gimnasio.
* Género: Género del miembro del gimnasio (masculino o femenino).
* Peso (kg): Peso del miembro en kilogramos.
* Altura (m): Altura del miembro en metros.
* Max_BPM: Frecuencia cardíaca máxima (pulsaciones por minuto) durante las sesiones de entrenamiento.
* Avg_BPM: Frecuencia cardíaca promedio durante las sesiones de entrenamiento.
* Resting_BPM: Frecuencia cardíaca en reposo antes del entrenamiento.
* Session_Duration (horas): Duración de cada sesión de entrenamiento en horas.
* Calorías_Quemadas: Total de calorías quemadas durante cada sesión.
* Workout_Type: Tipo de entrenamiento realizado (por ejemplo, Cardio, Fuerza, Yoga, HIIT).
* Fat_Percentage: Porcentaje de grasa corporal del miembro.
* Consumo_de_agua (litros): Ingesta diaria de agua durante los entrenamientos.
* Frecuencia_de_entrenamiento (días/semana): Número de sesiones de entrenamiento por semana.
* Nivel_Experiencia: Nivel de experiencia, desde principiante (1) hasta experto (3).
* IMC: Índice de Masa Corporal, calculado a partir de la altura y el peso.

Dado que es un problema de regresión, la variable objetivo (Cantidad de calorias quemadas durante la sesión de entrenamiento) es continua.


## Brain storming

1. Predicción de Calorías Quemadas
Objetivo: Modelar la cantidad de calorías quemadas en función de las variables disponibles.
Variables predictoras: Edad, Género, Peso, Altura, Max_BPM, Avg_BPM, Resting_BPM, Session_Duration, Workout_Type, Fat_Percentage, Water_Intake, Workout_Frequency, Experience_Level, BMI.

2. Clasificación del Tipo de Entrenamiento a partir de Variables Fisiológicas
Objetivo: Predecir el Workout_Type en función de variables como Max_BPM, Avg_BPM, Resting_BPM, Calories_Burned, Session_Duration y BMI.

3. Duracion de la sesión ideal 
Variables predictoras: Edad, Género, Peso, Altura, Max_BPM, Avg_BPM, Resting_BPM, Session_Duration, Workout_Type, Fat_Percentage, Workout_Frequency, Experience_Level, BMI.

4. Impacto del Nivel de Hidratación en el Rendimiento
Objetivo: Analizar cómo el Water_Intake afecta variables como Max_BPM, Avg_BPM, Calories_Burned o Session_Duration.


Decidimos trabajar en las ideas 1 y 4.

## Cargar paquetes necesarios

```{r}

library(ggplot2)
library(car) # pruebas de diagnóstico
library(lmtest) # prueba de homocedasticidad
library(dplyr) # manipulación de datos
library(GGally) # visualización avanzad
library(HistData) # datos históricos de Galton
library(gridExtra) # organizar múltiples gráficos
library(caret)
library(corrplot)
library(MASS) 
library(tidyverse)
library(minpack.lm)
library(glmnet)
```


# 1. Data undestandig

## Cargamos los datos.
```{r}
datos <- read.csv("gym_members_exercise_tracking.csv")
```
```{r include=FALSE}
datos <- datos %>% 
  rename(Weight = Weight..kg., 
         Height = Height..m., 
         Session_Duration = Session_Duration..hours., 
         Water_Intake = Water_Intake..liters., 
         Workout_Frequency = Workout_Frequency..days.week.)
```

## Tamaño del dataset.
```{r}
size <- dim(datos)
```

En estos datos podemos ver que tenemos un total de `r size[1]` observaciones y `r size [2]` variables en este dataset.

## Variables.
```{r}
str(datos)
```

Al ver esto podemos ver que estos datos son en su mayoría de tipo numérico o entero, sin embargo, tenemos dos variables de tipo cadena de caracteres (`char`), `Gender` y `Workout_Type`.

## Valores faltantes.
```{r}
sum(is.na(datos))
```

Vemos que no tenemos ningún dato faltante o missing entre nuestros datos.

## Primer vistazo a los datos.
```{r}
head(datos, 5)
```
Realizamos la partición de nuestros datos.

```{r}
# Ponemos una semilla para que la partición sea siempre la misma
set.seed(1)

# Buscamos los indices para la parte de train y de test y val
indices_train <- createDataPartition(datos$Calories_Burned, p = 0.7, list = FALSE)

# Creamos la variable train y test_val
train <- datos[indices_train, ]
test_val <- datos[-indices_train, ]

# Buscamos los indices para test
indices_test <- createDataPartition(test_val$Calories_Burned, p = 0.5, list = FALSE)

# Creamos la variabe test y val
test <- test_val[indices_test, ]
val <- test_val[-indices_test, ]
```

Miramos la información de nuestros datos de entrenamiento

```{r}
dim(train)
head(train)
str(train)
```

# 2. EDA

Antes de nada vamos a ver información de nuestra variable objetivo importante
```{r}
summary(train$Calories_Burned)
```
Con esto nos da una idea de la cantidad de calorias que las personas pueden quemar, vemos como la media es casi 900 kcalorías y vemos tambien que el mínimo es de unas 300 kcal y el máximo es de 1700 kcal. 

Vamos a ver la forma de nuestra variable objetivo gráficamente.
```{r}
train |> ggplot(mapping = aes(x = Calories_Burned)) +
  geom_histogram(bins = 30) +
  theme_bw()
```

Viendo este histograma se puede ver como las calorias quemadas se acerca a una distribución normal, viendo los datos de anteriores, comprobamos que este histograma si que tiene sentido. 


## Distribucion de Calories_burned por genero

```{r}
train |> ggplot(aes(x = Gender, y = Calories_Burned, fill = Gender)) +
  geom_boxplot() +
  labs(title = "Distribución de Calorías Quemadas por Género",
       x = "Género", y = "Calorías Quemadas") +
  theme_minimal()

```

Este gráfico permite analizar si hay diferencias significativas en las calorías quemadas entre hombres y mujeres, podemos observar que la media de calorías quemadas en hombres es ligeramente mayor aunque no hay una diferencia significativa.

## Relación entre Calories_Burned y Session_Duration

```{r}
train |> ggplot(aes(x = Session_Duration, y = Calories_Burned)) +
  geom_point(alpha = 0.5, color = "blue") +
  geom_smooth(method = "lm", color = "red") +
  labs(title = "Relación entre Duración del Entrenamiento y Calorías Quemadas",
       x = "Duración del Entrenamiento (horas)", y = "Calorías Quemadas") +
  theme_minimal()

```
Podemos ver que hay una tendencia clara entre el tiempo de entrenamiento y las calorías quemadas

## Relación entre Calories_Burned y avg_bpm
```{r}
train |> ggplot(aes(x = Avg_BPM, y = Calories_Burned)) +
  geom_point(alpha = 0.5, color = "blue") +
  geom_smooth(method = "lm", color = "red") +
  labs(title = "Relación entre avg BPM y Calorías Quemadas",
       x = "AVG_BPM", y = "Calorías Quemadas") +
  theme_minimal()

```
En el gráfico observamos la relación entre el average BPM y las calorías quemadas. Se observa una ligera tendencia positiva, representada por la línea de regresión en rojo, lo que indica que a mayor average bpm, mayor es la cantidad de calorías quemadas. Aunque la dispersión de los puntos indica que existen variaciones significativas entre los datos, lo que sugiere que influyen otros factores como la duración de la sesión, el género o el tipo de entrenamiento.

## Impacto del Nivel de Hidratación en el Rendimiento

### Relación entre Water_Intake y Calories_Burned

```{r}
train |> ggplot(aes(x = Water_Intake, y = Calories_Burned)) +
  geom_point(alpha = 0.5, color = "blue") +
  geom_smooth(method = "lm", color = "red") +
  labs(title = "Relación entre Ingesta de Agua y Calorías Quemadas",
       x = "Consumo de Agua (litros)", y = "Calorías Quemadas") +
  theme_minimal()

```
Podemeos observar una tendencia positiva en la que mayor hidratación esté asociada con un mayor gasto calórico.


### Relación entre Water_Intake y Max_BPM / Avg_BPM

```{r}
train |> ggplot(aes(x = Water_Intake, y = Max_BPM)) +
  geom_point(alpha = 0.5, color = "blue") +
  geom_smooth(method = "lm", color = "red") +
  labs(title = "Relación entre Ingesta de Agua y Frecuencia Cardíaca Máxima",
       x = "Consumo de Agua (litros)", y = "Max BPM") +
  theme_minimal()

train |> ggplot(aes(x = Water_Intake, y = Avg_BPM)) +
  geom_point(alpha = 0.5, color = "blue") +
  geom_smooth(method = "lm", color = "red") +
  labs(title = "Relación entre Ingesta de Agua y Frecuencia Cardíaca Promedio",
       x = "Consumo de Agua (litros)", y = "Avg BPM") +
  theme_minimal()

```
Por lo que se observa en la imagen, la relación entre la ingesta de agua y la frecuencia cardíaca máxima (Max BPM) es prácticamente inexistente. La línea de tendencia roja es casi horizontal, lo que indica una correlación muy baja o nula entre estas variables.

### Comparación del rendimiento cardíaco según niveles de hidratación

```{r}
train %>%
  mutate(Water_Intake_Level = case_when(
    Water_Intake < 2 ~ "Baja",
    Water_Intake >= 2 & Water_Intake < 3 ~ "Media",
    Water_Intake >= 3 ~ "Alta"
  )) %>%
  ggplot(aes(x = Water_Intake_Level, y = Avg_BPM, fill = Water_Intake_Level)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Frecuencia Cardíaca Promedio según Consumo de Agua",
       x = "Nivel de Ingesta de Agua",
       y = "Frecuencia Cardíaca Promedio (BPM)") +
  theme_minimal() +
  scale_fill_manual(values = c("red", "yellow", "green"))

```

```{r}
cor.test(train$Water_Intake, train$Avg_BPM)

```
El resultado del test de correlación de Pearson indica que no hay una relación significativa entre el consumo de agua y la frecuencia cardíaca promedio (Avg_BPM):

Coeficiente de correlación (r): 0.0067 → Casi nula, lo que sugiere que no hay una asociación lineal entre ambas variables.
p-valor: 0.8608 → Muy alto, lo que significa que no podemos rechazar la hipótesis nula (es decir, no hay evidencia estadística de una relación).
Intervalo de confianza al 95%: [-0.068, 0.081] → Incluye el 0, reforzando que la relación es débil o inexistente.


```{r}
ggplot(train, aes(x = Water_Intake, y = Session_Duration)) +
  geom_point(color = "blue", alpha = 0.5) +
  geom_smooth(method = "lm", color = "red", se = TRUE) +
  labs(title = "Relación entre Ingesta de Agua y Duración del Entrenamiento",
       x = "Consumo de Agua (litros)", 
       y = "Duración del Entrenamiento (horas)") +
  theme_minimal()

```
Observamos una pendiente positiva, indicando que las personas más hidratadas entrenan por más tiempo.

### Correlación entre Consumo de Agua y Duración del Entrenamiento

```{r}
cor.test(train$Water_Intake, train$Session_Duration)

```
Relación entre Consumo de Agua y Duración del Entrenamiento

Correlación: 0.246 (moderada)
p-valor: 6.23e-11 (muy significativo)

 Hay una relación positiva y significativa entre la ingesta de agua y la duración del entrenamiento. Esto sugiere que las personas que se hidratan más tienden a entrenar por más tiempo.


### Correlación entre Consumo de Agua y Calorías Quemadas

```{r}
cor.test(train$Water_Intake, train$Calories_Burned)

```

Correlación: 0.330 (moderada)
p-valor: < 2.2e-16 (extremadamente significativo)

Existe una relación clara entre la hidratación y la cantidad de calorías quemadas. Esto indica que una mayor ingesta de agua podría estar asociada con un mayor gasto energético durante el ejercicio.




# 3. Modelización estadística.
Nuestro problema para analizar es ver si hay alguna relación positiva entre las calorías que quema una persona por duración del entrenamineto, con esto buscamos como objetivo determinar si cuanto más tiempo una persona entrene, más kcalorías quema durante el entrenamiento. 

Las variables que se involucran sería el tiempo de duración de las sesiones de entrenamiento (variable explicativa) y la cantidad de calorías que quema una persona (variable respuesta).

Miramos los datos de la variable explicativa

```{r}
summary(train$Session_Duration)
```

Podemos ver que las personas entrenan una media de 1.256 horas, lo que hace 1 hora y 15 minutos, además podemos ver que dentro de los datos registrados, el mínimo de horas que se ha almacenado es de 0.5 horas y el máximo es de 2 horas.

Observamos los datos de esas dos variables.
```{r}
variables_objetivo <- select_(train, "Calories_Burned", "Session_Duration")
head(variables_objetivo, 5)
```


Viendo esta cabecera, se puede ver a simple vista que si que puede haber una realción entre la duración de el entrenamiento con las calorías que se queman, para verlo más claro, representamos ambas variables graficamente.

```{r}
train |>
  ggplot(mapping = aes(x = Calories_Burned, y = Session_Duration)) +
  geom_point()
```

Dado que tenemos una relación positiva entre estas dos variables, vamos a proponer un modelo para relacionar estas dos variables. Buscamos mediante el método de mínimos cuadrados hallar los valores de $\beta_0$ y $\beta_1$ para poder llegar a un modelo con la forma: $\text{Calorias} = \beta_0 + \beta_1 \text{(Tiempo de entrenamient0)} + \epsilon$.

```{r}
# Creamos el modelo lineal y lo analizamos
model <- lm(Calories_Burned ~ Session_Duration, data = train)
summary(model)
```
observamos que el valor del intercepto es de 5,659 aunque midiendo el tiempo en horas no es muy relevante que con o horas entrenadas quemes 5,659

la pendiente tiene un valor de 714.1 es decir por cada hora extra a la sesión de entrenamiento se queman 714.1 calorías más en promedio

al tener un p value < 2.2e^-16 podemos afirmar que la duración es altamente significativa

observamos que R^2 es 0.8114 un ajuste bastante bueno

Error estándar de los residuos = 116: En promedio, las predicciones de nuestro modelo tienen un error de ±116 calorías.

Ahora vamos a ver el modelo gráficamente.

```{r}
train |> 
  ggplot(mapping = aes(x = Calories_Burned, y = Session_Duration)) +
  geom_point() +
  geom_smooth(method = "lm", col = "red") +
  labs(title = "Relación entre calorias quemadas y la duración de la sesion.",
       x = "Calorias quemadas.",
       y = "Duración de la sesion.") +
  annotate("text", x = 500, y = 2.0, label = paste("y =", round(coef(model)[1], 2), "+", round(coef(model)[2], 2), "x"), color = "red")
```

La linea nos muestra una relación creciente según las calorías quemadas y el tiempo de entrenamiento. Que el valor de $\beta_0$ sea menor a 0 no nos importa mucho, debido a que el mínimo es 0.5 (media hora) por lo que nunca va a ser negativo ya que $\beta_1$ es 721.79 

## Correlación

Vamos a calcular y entender la correlación entre las variables de nuestro estudio.

```{r}
# Cogemos solo las variables numéricas para hacer matrices de correlación
train_num <- select_if(train, is.numeric)

# Matriz de correlación de variables cuantitativas.
m <- cor(train_num, use = "complete.obs")
corrplot(m,type = "upper", method="number")
```

## Covarianza
```{r}
calorias <- train$Calories_Burned
sesion <- train$Session_Duration

covarianza <- round(cov(calorias, sesion), 3)

print(paste("La covarianza entre la calorias quemadas por la sesion de entrenamiento es: ", covarianza))
```

Con esta covarianza podemos observar que ambas variables aumentan juntas, además de que no es cercana a 0 por lo que entre estas variables existe una relación lineal.

## Coeficiente de correlación de lineal.
Calculamos y mostramos el coeficiente de correlación de Pearson entre la duración de las sesiones de ejercicio y las calorías quemadas.

```{r}
correlacion_pearson <- cor(train$Session_Duration, train$Calories_Burned, use = "complete.obs")
cat("El coeficiente de correlación de Pearson entre la duración de la sesión y las calorías quemadas es:", round(correlacion_pearson, 8), "\n")
```

La correlación de Pearson nos confirma lo que habíamos visto calculando la covarianza, como es cercano a 1, existe una relación lineal fuerte entre las variables y a su vez al ser positivo, las variables aumentan a la par.

## Tabla ANOVA

```{r}
# Ajustar el modelo de regresión lineal
modelo <- lm(Calories_Burned ~ Age + Gender  + Height+ Weight + Max_BPM + Avg_BPM + Resting_BPM + Session_Duration+ Calories_Burned + Workout_Type + Fat_Percentage + Water_Intake + Workout_Frequency + Experience_Level + BMI , data = train)

# Obtener la tabla ANOVA
tabla_anova <- anova(modelo)
cat("Tabla ANOVA:\n")
#mostrar tabla anova
print(tabla_anova)
```
tras realizar el analísis de la tabla de varianza (ANOVA) podemos concluir que los factores más influyentes son 
la duración de la sesión, el average BPM, el género y el año. Luego encontramos factores influyentes pero en menor medida como el BMI y la altura. 

## 3.1 Análisis de Residuos

Realizamos el análisis de residuos para evaluar el modelo ajustado.

### Residuos vs Valores Ajustados

```{r}
# Obtener los residuos
residuos <- resid(model)
valores_ajustados <- fitted(model)

# Graficar residuos vs valores ajustados
plot(valores_ajustados, residuos,
     main = "Residuos vs Valores Ajustados",
     xlab = "Valores Ajustados",
     ylab = "Residuos",
     pch = 19, col = "blue")
abline(h = 0, col = "red", lwd = 2)

```
Podemos observar que los residuos se distribuyen de manera aleatoria alrededor del eje, sin mostrar patrones claros, por lo que el supuesto de linealidad se cumple. 



### Histograma de los Residuos
```{r}
# Graficar histograma de los residuos
hist(residuos,
     main = "Histograma de Residuos",
     xlab = "Residuos",
     col = "lightblue", border = "black")

```
Podemos observar que nuestra distribución se acerca a una distribucion normal con un ligero desplazamiento a la izquierda. 



### QQ-Plot de los Residuos


```{r}

# Graficar QQ-plot de los residuos
qqnorm(residuos, main = "QQ-Plot de los Residuos")
qqline(residuos, col = "red", lwd = 2) 

```
podemos observar que los puntos se alinean con la linea roja diagonal, por lo que podemos deducir que siguen una distribución normal y concuerda con lo esperado.



### Prueba de Normalidad de los Residuos (Shapiro-Wilk)

```{r}
# Realizar la prueba de Shapiro-Wilk para normalidad de los residuos

shapiro_test <- shapiro.test(residuos)
cat("Prueba de Shapiro-Wilk para normalidad de los residuos:\n")
print(shapiro_test)

```
Observamos que el p-valor obtenido es menor que 0.05, por lo que rechazaríamos la Hipótesis nula.





## 3.2 Diagnóstico del Modelo: Pruebas de Homocedasticidad y Leverage

### Prueba de Homocedasticidad (Breusch-Pagan)

```{r}
# Realizar la prueba de Breusch-Pagan para homocedasticidad
bptest_result <- bptest(model)
cat("\nPrueba de Breusch-Pagan para homocedasticidad:\n")
print(bptest_result)

```
La prueba de Breusch-Pagan muestra un valor p muy pequeño (< 2.2e-16), lo que indica que hay heterocedasticidad en el modelo. Esto significa que los errores del modelo no tienen una varianza constante, lo que puede afectar la precisión de los resultados. En términos más simples, la relación entre las variables puede cambiar dependiendo de ciertos factores, como la experiencia en el gimnasio o características físicas de los usuarios. Para corregir esto, se pueden hacer algunos ajustes, como transformar los datos, usar otro tipo de regresión o aplicar correcciones estadísticas para mejorar la fiabilidad del análisis.


### Análisis de Leverage 

Calculamos el leverage de las observaciones y graficamos las observaciones con leverage alto.

```{r}
# Calcular leverage
leverage <- hatvalues(model)

# Umbral para leverage alto
n <- nrow(train)
p <- length(coef(train))  # Número de parámetros (incluyendo el intercepto)
leverage_threshold <- 2 * p / n

# Identificar observaciones con leverage alto
leverage_high <- which(leverage > leverage_threshold)

cat("\nUmbral para leverage alto:", leverage_threshold, "\n")
cat("\nObservaciones con leverage alto (si las hay):\n")
print(leverage_high)

# Gráfico de leverage
grafico_leverage <- ggplot(data.frame(leverage), aes(x = seq_along(leverage), y = leverage)) +
  geom_point(color = "blue") +
  geom_hline(yintercept = leverage_threshold, col = "red", lwd = 2, lty = 2) +
  labs(title = "Leverage de las Observaciones", x = "Índice de Observación", y = "Leverage")

# Mostrar gráfico
grafico_leverage
```

El gráfico de leverage muestra la influencia de cada observación en los coeficientes del modelo. Observaciones con leverage alto (por encima del umbral) tienen un gran efecto en el ajuste del modelo.
El gráfico de leverage muestra que la mayoría de las observaciones tienen un leverage bajo, lo que indica que no influyen demasiado en el ajuste del modelo. Sin embargo, hay una dispersión uniforme de puntos a ambos lados de la línea roja discontinua en niveles más altos de leverage. Esto sugiere que algunas observaciones tienen un mayor impacto en los coeficientes del modelo y podrían ser casos atípicos o influyentes. Es importante analizar estos puntos para determinar si afectan negativamente la estabilidad del modelo y, si es necesario, considerar ajustes o métodos robustos.


### Análisis de la Distancia de Cook

 mide la influencia de cada observación sobre los coeficientes del modelo.

```{r}
# Calcular Distancia de Cook
cooks_distance <- cooks.distance(model)

# Gráfico de Distancia de Cook
grafico_cooks_distance <- ggplot(data.frame(cooks_distance), aes(x = seq_along(cooks_distance), y = cooks_distance)) +
  geom_point(color = "blue") +
  geom_hline(yintercept = 4 / n, col = "red", lwd = 2, lty = 2) +
  labs(title = "Distancia de Cook", x = "Índice de Observación", y = "Distancia de Cook")

# Mostrar gráfico
grafico_cooks_distance

```

La distancia de Cook mide la influencia de cada observación sobre los coeficientes del modelo. Observaciones con una distancia de Cook alta (por encima del umbral) pueden ser altamente influyentes. En el gráfico, hay algunas observaciones con distancia de Cook alta, lo que indica que estas observaciones pueden estar afectando de manera desproporcionada el ajuste del modelo
Podemos observar que la mayoría de las observaciones tienen una influencia baja en el modelo, ya que están acumuladas en la parte inferior, cerca de la línea roja. Sin embargo, hay algunas observaciones con una distancia de Cook alta, lo que indica que pueden estar afectando de manera significativa el ajuste del modelo. Estos puntos atípicos podrían estar influyendo de manera desproporcionada en los coeficientes, por lo que sería recomendable revisarlos para determinar si representan datos válidos o si es necesario aplicar ajustes para mejorar la estabilidad del modelo.

## 3.3 Análisis de DFFITS

mide el cambio en los valores ajustados cuando se omite una observación.

```{r}
# Calcular DFFITS
dffits_values <- dffits(model)

# Gráfico de DFFITS
grafico_dffits <- ggplot(data.frame(dffits_values), aes(x = seq_along(dffits_values), y = dffits_values)) +
  geom_point(color = "green") +
  geom_hline(yintercept = c(2 * sqrt(length(coef(model)) / n)), col = "red", lwd = 2, lty = 2) +
  labs(title = "DFFITS", x = "Índice de Observación", y = "DFFITS")

# Mostrar gráfico
grafico_dffits

```

El gráfico de DFFITS muestra que la mayoría de las observaciones tienen poca influencia en el modelo, ya que están acumuladas alrededor de cero y dentro del rango de ±0.1, sin sobrepasar la línea roja. Sin embargo, hay algunas observaciones que superan este umbral, lo que indica que pueden estar afectando significativamente los valores ajustados. Estas observaciones deberían revisarse para determinar si representan datos válidos o si están distorsionando el modelo, ya que podrían influir en la precisión de las predicciones


## 3.4 Análisis de DFBETAS

nos indican la influencia de cada observación sobre cada coeficiente de la regresión.


```{r}
# Calcular DFBETAS# Calcular DFBETAS
dfbetas_values <- dfbetas(model)

# Convertir dfbetas_values a un data.frame para poder usarlo en ggplot
dfbetas_df <- as.data.frame(dfbetas_values)

# Graficar DFBETAS para el coeficiente de la pendiente (segunda columna si existe)
grafico_dfbetas <- ggplot(dfbetas_df, aes(x = seq_along(dfbetas_df[,2]), y = dfbetas_df[,2])) + # Usamos el coeficiente de la pendiente
  geom_point(color = "purple") +
  geom_hline(yintercept = 2 / sqrt(n), col = "red", lwd = 2, lty = 2) +
  labs(title = "DFBETAS para el Coeficiente de la Pendiente", x = "Índice de Observación", y = "DFBETAS")

# Mostrar gráfico
grafico_dfbetas


```
El gráfico de DFBETAS muestra que la mayoría de las observaciones tienen poca influencia en los coeficientes del modelo, ya que están acumuladas alrededor de cero y dentro del rango de ±0.1, sin sobrepasar la línea roja. Sin embargo, algunas observaciones superan este umbral, lo que indica que pueden estar afectando de manera significativa los coeficientes de regresión. Es importante revisar estos puntos para determinar si están influyendo de manera desproporcionada en el modelo y, si es necesario, considerar ajustes para mejorar su estabilidad.

# 4. Seleccion de variables

Método Forward

```{r}
# Modelo vacío (sin variables)
modelo_vacio <- lm(Calories_Burned ~ 1, data = train)

# Selección hacia adelante (Forward Selection)
modelo_forward <- step(modelo_vacio, 
                       scope = ~ Age + Gender + Weight + Height +Max_BPM+ Avg_BPM + Resting_BPM + 
                                Session_Duration + Workout_Type +Fat_Percentage +Water_Intake + BMI + Workout_Frequency+ Experience_Level, 
                       direction = "forward")

# Ver resumen del modelo seleccionado
summary(modelo_forward)

```

El modelo final tras usar el método forward incluye las siguientes variables: Session_Duration, Avg_BPM, Gender, Age, Resting_BPM, y Workout_Type

Resultados:
R²: 0.979 esto indica que el modelo explica aproximadamente el 97.9% de la variabilidad en las calorías quemadas.
AIC: 5025.39, que es un valor bastante bajo, lo que sugiere un buen ajuste del modelo.
Coeficientes:
Session_Duration tiene un coeficiente positivo y significativo, lo que indica que a mayor duración de la sesión, mayor cantidad de calorías quemadas.
Avg_BPM y Gender también son muy significativos, tienen bastante impacto en la cantidad de calorías quemadas.
Age tiene un coeficiente negativo, lo que sugiere que, a medida que la edad aumenta, las calorías quemadas tienden a disminuir, aunque en una magnitud pequeña.
Resting_BPM tiene un coeficiente positivo, indicando que a mayor BPM en reposo, mayor número de calorías quemadas.
Workout_Type tiene un coeficiente negativo, pero no es muy diferente de cero (p > 0.05), lo que puede indicar que no es una variable determinante en este caso.

Método Backward

```{r}
# Ajustamos el modelo inicial con todas las variables
modelo_inicial <- lm(Calories_Burned ~ Age + Gender + Weight + Height +Max_BPM+ Avg_BPM + Resting_BPM + 
                                Session_Duration + Workout_Type +Fat_Percentage +Water_Intake + BMI + Workout_Frequency+ Experience_Level,  data = train)

# Aplicamos el método backward para la eliminación de variables
modelo_backward <- step(modelo_inicial, direction = "backward", trace = 1)

# Mostrar resumen del modelo final después de la selección
summary(modelo_backward)


```

El modelo final, después de aplicar el método backward, utiliza las siguientes variables:
Age, Gender, Avg_BPM, Session_Duration ya que tienen coeficientes significativos con valores p menores a 0.05, lo que indica que estas variables tienen un impacto relevante sobre Calories_Burned.

Se han eliminaron variables como Max_BPM, water_intake, fat_percentage,  workout_frecuency y experience_level debido a su baja contribución al modelo. El R² de 0.9792 indica que el modelo explica el 97.92% de la variabilidad en las calorías quemadas. El error estándar residual de 39.12 sugiere que el modelo tiene una variabilidad de aproximadamente 39.12 calorías en las predicciones.Estadística F de 3523 con un p-valor muy pequeño (menor a 2e-16), lo que indica que el modelo en su conjunto es altamente significativo. Aunque el modelo es preciso, variables como workout_type no son del todo significativas y podrían eliminarse para mejorar el modelo.

Método Stepwise

```{r}

# Modelo completo: Usamos todas las variables
modelo_completo <- lm(Calories_Burned ~ ., data = train)

# Aplicar el método Stepwise (tanto Forward como Backward)
modelo_stepwise <- step(modelo_completo, direction = "both", trace = 1)

# Ver el resumen del modelo ajustado
summary(modelo_stepwise)



```
El modelo tiene un R² de 0.9792, lo que indica que explica el 97.92% de la variabilidad en las calorías quemadas, lo cual podemos considerar un buen ajuste. El error residual estándar es de 39.12, por tanto las predicciones del modelo tienen un error promedio de 39.12 calorías. El estadístico F es 3523 con un p-valor muy bajo lo que indica que el modelo en su conjunto es altamente significativo. Se han eliminado variables como Max_BPM, Water_Intake, Fat_Percentage y Experience_Level, al no mejorar el ajuste del modelo. Las variables más influyentes son Age, Gender, Avg_BPM y Session_Duration, con un impacto directo en las calorías quemadas.


método lasso

```{r}
train$Gender <- as.numeric(as.factor(train$Gender))
train$Workout_Type <- as.numeric(as.factor(train$Workout_Type))

# ---- 1. Preparar los datos ----
# Separar variables predictoras (X) y la variable objetivo (y)
X <- as.matrix(train[, -which(names(train) == "Calories_Burned")])  # Matriz de predictores
y <- train$Calories_Burned  # Variable objetivo

# ---- 2. Ajustar modelo Lasso ----
set.seed(123)  # Fijar semilla para reproducibilidad
modelo_lasso <- cv.glmnet(X, y, alpha = 1,  # Lasso (alpha = 1)
                          nfolds = 10,  # Validación cruzada 10-fold
                          type.measure = "mse")  # Minimizar el error cuadrático medio

# ---- 3. Obtener la mejor lambda ----
lambda_opt <- modelo_lasso$lambda.min
cat("Mejor lambda:", lambda_opt, "\n")

# ---- 4. Hacer predicciones ----
y_pred <- predict(modelo_lasso, s = lambda_opt, newx = X)

# ---- 5. Evaluación del modelo ----
mse <- mean((y - y_pred)^2)  # Error cuadrático medio
rmse <- sqrt(mse)  # Raíz del error cuadrático medio
r2 <- cor(y, y_pred)^2  # Coeficiente de determinación

cat("MSE:", mse, "\n")
cat("RMSE:", rmse, "\n")
cat("R²:", r2, "\n")

# ---- 6. Ver coeficientes seleccionados por Lasso ----
coeficientes <- coef(modelo_lasso, s = lambda_opt)
print(coeficientes)


```

Ridge

```{r}
# Preparar los datos
# Crear la matriz de características X (sin la variable dependiente)
X <- as.matrix(train[, -which(names(train) == "Calories_Burned")])

# Crear el vector de la variable dependiente Y
y <- train$Calories_Burned

# Ajustar el modelo Ridge con validación cruzada (alpha = 0)
modelo_ridge <- cv.glmnet(X, y, alpha = 0)

# Ver el valor óptimo de lambda
cat("Mejor lambda:", modelo_ridge$lambda.min, "\n")

# Resumen del modelo
summary(modelo_ridge)

# Graficar la curva de validación cruzada
plot(modelo_ridge)

# Hacer predicciones con el valor óptimo de lambda
y_pred_ridge <- predict(modelo_ridge, s = "lambda.min", newx = X)

# Calcular el MSE (Error Cuadrático Medio)
mse_ridge <- mean((y - y_pred_ridge)^2)
cat("MSE del modelo Ridge:", mse_ridge, "\n")

# Calcular el RMSE (Raíz del Error Cuadrático Medio)
rmse_ridge <- sqrt(mse_ridge)
cat("RMSE del modelo Ridge:", rmse_ridge, "\n")

# Calcular el R² (Coeficiente de Determinación)
r2_ridge <- 1 - sum((y - y_pred_ridge)^2) / sum((y - mean(y))^2)
cat("R² del modelo Ridge:", r2_ridge, "\n")
```

elastic_net
 
```{r}
# Preparar los datos
X <- as.matrix(train[, -which(names(train) == "Calories_Burned")])
y <- train$Calories_Burned

# Ajustar el modelo Elastic Net
# alpha = 0.5 es una mezcla equilibrada entre Ridge y Lasso
modelo_elastic_net <- cv.glmnet(X, y, alpha = 0.5)

# Ver el mejor valor de lambda
cat("Mejor lambda para Elastic Net:", modelo_elastic_net$lambda.min, "\n")

# Resumen del modelo
summary(modelo_elastic_net)

# Hacer predicciones con el valor óptimo de lambda
y_pred_elastic_net <- predict(modelo_elastic_net, s = "lambda.min", newx = X)

# Calcular el MSE (Error Cuadrático Medio)
mse_elastic_net <- mean((y - y_pred_elastic_net)^2)
cat("MSE del modelo Elastic Net:", mse_elastic_net, "\n")

# Calcular el RMSE (Raíz del Error Cuadrático Medio)
rmse_elastic_net <- sqrt(mse_elastic_net)
cat("RMSE del modelo Elastic Net:", rmse_elastic_net, "\n")

# Calcular el R² (Coeficiente de Determinación)
r2_elastic_net <- 1 - sum((y - y_pred_elastic_net)^2) / sum((y - mean(y))^2)
cat("R² del modelo Elastic Net:", r2_elastic_net, "\n")

```

comparacion de los tres modelo 
Elastic Net tiene un R² de 0.979 y un RMSE de 38.98. Este modelo muestra un buen ajuste a los datos, con el 97.9% de la variabilidad en las calorías quemadas. La combinación de penalizaciones de Ridge y Lasso le permite manejar bien tanto la multicolinealidad como realizar una selección de variables. Aunque su MSE es de 1519.821, este valor se encuentra dentro de un rango razonable.

Ridge, por su parte, tiene un R² de 0.9676 y un RMSE de 48.42, lo que indica que aunque el modelo también tiene un buen ajuste, no es tan preciso como Elastic Net en términos de predicción.Su MSE es de 2344.048, es decir, más alto en comparación con los otros dos modelos.

Lasso es bastante similar al modelo Elastic Net, con un R² de 0.979 y un RMSE de 38.98. Al igual que Elastic Net, Lasso ha realizado una selección de variables, eliminando aquellas que no aportan significativamente a la predicción en nuestro caso Gender, Max_BPM, Workout_Type, Water_Intake, Experience_Level.

Como observamos en el modelo Elastic Net tenemos un lambda de 1.046946 que indica que el modelo ha encontrado un equilibrio adecuado entre la penalización y el ajuste a los datos. se ha mantenido el R^2 en 0.979 sin embargo hemos conseguido un MSE de 1519.821 lo que es bastante razonable. El RMSE de 38.98 lo que significa que nuestros datos se desplazan aproximadamente 38.98 de los valores reales que en comparacion con el anterior hemos conseguido bajar.

Tabla comparativa de todos los modelos 

```{r}
# Crear una tabla comparativa 
comparativa_modelos <- data.frame(
  Modelo = c("Elastic Net", "Ridge", "Lasso", "Forward Selection", "Backward Selection"),
  R2 = c(0.979, 0.9676, 0.979, 0.979, 0.9792),
  RMSE = c(38.98, 48.42, 38.98, 39.12, 39.12),
  MSE = c(1519.82, 2344.048, 1519.82, 1524.98, 1524.98),
  Lambda = c(1.046946, NA, NA, NA, NA)
)

# Mostrar la tabla comparativa
print(comparativa_modelos)

```

Tras comparar los distintos modelos de regresión, observamos que Elastic Net y Lasso ofrecenla mayor efectividad con un R² de 0.979 y un RMSE de 38.98, lo que sugiere una alta capacidad para explicar la variabilidad en las calorías quemadas con un error relativamente bajo. Ridge, por otro lado, presenta un R² menor (0.9676) y un RMSE mayor (48.42), lo que indica que es menos preciso en sus predicciones. Los modelos de selección de variables (Forward, Backward y Stepwise) también tienen un buen ajuste (R² = 0.979), pero al depender de la selección manual de variables pueden no manejar bien la multicolinealidad.

Al analizar los distintos métodos vemos que las variables más eliminadas son  Max_BPM, Water_Intake, Fat_Percentage y Experience_Leve lo que indica que variables que no nos dan una  información relevante. Session_Duration, Avg_BPM, Gender y Age aparecen constantemente, lo que nos confirma su importancia en la predicción. En particular, Session_Duration y Avg_BPM destacan como los factores más determinantes, ya que el tiempo de entrenamiento y la intensidad del esfuerzo medido en BPM tienen una relación directa con la quema de calorías.


# 5. Modelo de regresión lineal multiple.

Tras haber visto la matriz de correlación de las variables y haber hecho la selección de variables, vamos a ver cual es el mejor modelo multiple para poder predecir nuestra varible, primero vamos a ver el modelo con la matriz de correlación.

```{r}
modelo_multiple <- lm(Calories_Burned ~ Session_Duration + Fat_Percentage + Water_Intake + Experience_Level + Avg_BPM + Age, data = train)
summary(modelo_multiple)
```
Seleccionando las varibles que tiene más de |0.4| de relación con nuestra bariable objetivo, tenemos un modelo con un R2 multiple de 0.967 y uno ajustado de 0.9667, que está muy bien ya que nos dice que nuestro modelo es bastante bueno. Ahora vamos a ver como se ven los residuos del modelo y los vamos a nalizar.

```{r}
# Obtener los residuos
residuos_multiple <- resid(modelo_multiple)
valores_ajustados <- fitted(modelo_multiple)

# Graficar residuos vs valores ajustados
plot(valores_ajustados, residuos_multiple,
     main = "Residuos vs Valores Ajustados",
     xlab = "Valores Ajustados",
     ylab = "Residuos",
     pch = 19, col = "blue")
abline(h = 0, col = "red", lwd = 2)
```

Al ver los residuos contra los varlores ajustados, podemos ver como no hay una varianza constante, ya que el empezar varía poco respecto a la parte derecha del gráfico.

```{r}
# Graficar histograma de los residuos
hist(residuos_multiple,
     main = "Histograma de Residuos",
     xlab = "Residuos",
     col = "lightblue", border = "black")
```

Viendo este gráfico a simple vista, podemos deduri que nos acercamos a una distribución normal.

```{r}
qqnorm(residuos_multiple, main = "QQ-Plot de los Residuos")
qqline(residuos_multiple, col = "red", lwd = 2) 
```

Vemos con el qqplot que los residuos se acercan mucho a la linea roja, y que a sus extremos se van separando, por lo que podemos deducir que estos residuos, del modelo multiple, pueden seguir una distribución normal. Vamos a hacer la prueba de Shapiro-Wilk para ver si podemos rechazar que nuestros datos son normales.

```{r}
shapiro_test <- shapiro.test(residuos_multiple)
print(shapiro_test)
```

Como vemos, tenemos un p-valor de más de 0.05 lo que nos indica que podemos rechazar la hipótesis de normalidad de nuestros residuos. Ahora vamos a hacer la prueba de homocedasticidad.

```{r}
bptest_result <- bptest(modelo_multiple)
print(bptest_result)
```

Vemos que tenemos un p-valor demasiado pequeño, lo nos indica heterocedasticidad en nuestro odelo, esto nos da la información de que no tenemos un modelo con una varianza constante, como hemos visto antes, afectando así a la precisión de los residuos. Para esto vamos a hacer unos ajustes de transformación de variables usando boxcox y el logaritmo a la variable objetivo para ver si esto mejora.

Ahora vamos a analizar el modelo que se ha creado mediante la selección de variables. Par ello hemos elegido el modelo creado mediante el metodo forward y el modelo creado por el metodo stepwise. Primero vamos a ver el modelo del metodo forward.

```{r}
summary(modelo_forward)
```

Como ya hemos visto antes tenemos un R2 incluso mejor que el modelo multiple creado con la matriz de correlación, vemos que es practicamente 0.979 que es bastante precisión. Ahora vamos a ver los residuos del modelo y los vamos a analizar.

```{r}
# Obtener los residuos
residuos_fordward <- resid(modelo_forward)
valores_ajustados <- fitted(modelo_forward)

# Graficar residuos vs valores ajustados
plot(valores_ajustados, residuos_fordward,
     main = "Residuos vs Valores Ajustados",
     xlab = "Valores Ajustados",
     ylab = "Residuos",
     pch = 19, col = "blue")
abline(h = 0, col = "red", lwd = 2)
```

Vemos como se distribullen de una manera aleatoria por la gráfica, además de eso, vemos como más que con una recta se podría aprocimar más con una parábola, lo que nos podría dar a entender que los residuos siguen una función polinómica de grado 2. Ahora vamos a ver que distribución siguen.

```{r}
# Graficar histograma de los residuos
hist(residuos_fordward,
     main = "Histograma de Residuos",
     xlab = "Residuos",
     col = "lightblue", border = "black")
```

Podemos ver que siguen una distribución bastante normal con media 0 y ligeramente desplazado hacia la izquierda.

```{r}
# Graficar QQ-plot de los residuos
qqnorm(residuos_fordward, main = "QQ-Plot de los Residuos")
qqline(residuos_fordward, col = "red", lwd = 2) 

```
En el qqplot, vemos que en la parte central los residuos de asemejan mucho a la linea, sin embargo, también se ve que tirando a las colas estos residuos tienen mucha más variabilidad. Ahora, vamos a hacer la prueba de normalidad de los residuos.

```{r}
shapiro_test <- shapiro.test(residuos_fordward)
print(shapiro_test)
```

Como vemos, tenemos un p-valor que está pro debajo de 0.05, lo nos indica que no podemos rechazar la hipótesis de que nuestros residuos son normales. Ahora vamos a hacer la prueba de homocedasticidad.

```{r}
# Realizar la prueba de Breusch-Pagan para homocedasticidad
bptest_result <- bptest(modelo_forward)
print(bptest_result)
```

Como vemos, tenemos un p-valor que es por debajo de 0.05, por lo que tenemos un modelo que nos sugiere heterocedasticidad. Despues de ver  el modelo multiple y el creado mediante el método de forward, ahora, vamos a ver el modelo creado por stepwise, primero de todo vamos a ver el modelo.

```{r}
summary(modelo_stepwise)
```
Vemos que este modelo es el más preciso a la hora de predecir las calorias que quema una persona, ya que tenemos un R2 de 0.9791, lo que nos dice que es bastante más preciso. Una vez visto el modelo, vamos a ver los residuos y si siguen una distribución normal.

```{r}
# Obtener los residuos
residuos_stepwise <- resid(modelo_stepwise)
valores_ajustados <- fitted(modelo_stepwise)

# Graficar residuos vs valores ajustados
plot(valores_ajustados, residuos_stepwise,
     main = "Residuos vs Valores Ajustados",
     xlab = "Valores Ajustados",
     ylab = "Residuos",
     pch = 19, col = "blue")
abline(h = 0, col = "red", lwd = 2)
```

Estos residuos son bastante parecidos a los vistos con el modelo creado con forward, podemos ver como se distribullen de una forma aleatorioa y que más que una recta, lo que mejor ajusta a los residuos es un polinomio cuadrado, sin embargo, se ve que no hay demasiada variabilidad en el modelo. Viendo esto, vamos a ver si sigue una distribución normal o no.

```{r}
# Graficar histograma de los residuos
hist(residuos_stepwise,
     main = "Histograma de Residuos",
     xlab = "Residuos",
     col = "lightblue", border = "black")
```

Podemos ver como los residuos pueden seguir una distribución normal con media 0 y se ve que esta ligeramente desplazado hacia la izquierda. Vamos a ver el qqplot para ver como se ajustan los residuos a la recta.

```{r}
# Graficar QQ-plot de los residuos
qqnorm(residuos_stepwise, main = "QQ-Plot de los Residuos")
qqline(residuos_stepwise, col = "red", lwd = 2) 

```

Como con el modelo creado por el metodo fordward, los residuos en la parte central se ajustan bastante a la recta, sin embargo al irnos a los extremos, tenemos que los residuos se alejan bastante, por lo que podemos deducri que se cumple la normalidad en los residuos. No obstante, vamos a realizar la prueba de normalidad de Shapiro-Wilk para ver si las hipótesisi son ciertas.

```{r}
shapiro_test <- shapiro.test(residuos_stepwise)
print(shapiro_test)
```

Como podemos ver el p-valor es inferior a 0.05, lo nos indica que no se puede descartar la hipótesis de normalidad de nuestros residuos de este modelo. Ahora, vamos a ver la prueba de homocedasticidad del modelo.

```{r}
# Realizar la prueba de Breusch-Pagan para homocedasticidad
bptest_result <- bptest(modelo_stepwise)
cat("\nPrueba de Breusch-Pagan para homocedasticidad:\n")
print(bptest_result)
```
Al igual que el otro, vemos que tenemos un p-valor que es por debajo de 0.05, por lo que el modelo nos sugiere heterocedasticidad.

Habiendo visto estos tres modelos, hemos decidido quedarnos con el últipo, ya que es el modelo que es más preciso, además de tener unos residuos que siguien una distribución normal y porque, aunque la prueba de homocedasticidad está por debajo de 0.05, es la más alta de los tres modelos vistos anteriormente.

# 6. Modelos no lienales y transformación de variables.

Una vez vistos nuestros modelos de lineales simple y multiple, vamos a ver que transformación podemos hacer a nuestra variable objetivo de tal forma que podamos tener una mejor regresión.

## 6.1 Modelo no lineal simple.

En nuestro modelo lineal simple, hemos observado que en el modelo lineal simple hay mucha variablidad entre nuestras variables, podemos ver como al ver hacer la prueba de homocedasticidad vemos que nuestros datos tienen heterocedasticidad, para ello vamos a relizar el cambio a ambas variables por se parado y vamos a ver cual es la que mejor se adapta y nos da una mejor resolución. Primero vamos a ver la transformación de box-cox para ver cual es la transformación de variables que mejor se adapta a nuestro modelo

```{r}
# Ajuste de un modelo lineal simple
modelo_bc <- lm(Calories_Burned ~ Session_Duration, train)

# Aplicación de la transformación de Box-Cox
boxcox(modelo_bc)
```

Viendo esto tenemos que el valor óptimo de lambda con un 95% de seguridad esta en torno al 0.5, dado que es distinto de 0, la mejor transformación de variables que podemos tener es el logaritmo de la variable Y, en nuestro caso son Calories_Burned. Antes de nada, vamos a ver como se ve gráficamente nuestra variable comparado con antes.

```{r}
train |> ggplot(aes(x = Session_Duration, y = log(Calories_Burned))) +
  geom_point(alpha = 0.5, color = "blue") +
  geom_smooth(method = "lm", color = "red") +
  labs(title = "Relación entre Duración del Entrenamiento y Calorías Quemadas",
       x = "Duración del Entrenamiento (horas)", y = "Calorías Quemadas") +
  theme_minimal()
```

A simple vista, podemos ver que gráficamente ha mejorado bastante la variabilidad de nuestros datos, a continuación, vamos a crear el modelo aplicando el logaritmo a nuestra variable objetivo.

```{r}
model_log <- lm(log(Calories_Burned) ~ Session_Duration, train)
summary(model_log)
```

viendo el modelo modificado, podemos ver como el Rcuadrado a aumentado un poco, hemos pasado de un 0.81 a un 0.82, ahora vamos a ver como se ven los residuos y vamos a hacer la prueba de homocedasticidad para ver si ha mejorado. Además de esto, podemos ver que el p-valor del intercepto ha mejorado significativamente, al principio su tenia un p-valor de 0.7 y ahora tenemos un p-valor menor a 2e-16.

```{r}
# Obtener los residuos
residuos <- resid(model_log)
valores_ajustados <- fitted(model_log)

# Graficar residuos vs valores ajustados
plot(valores_ajustados, residuos,
     main = "Residuos vs Valores Ajustados",
     xlab = "Valores Ajustados",
     ylab = "Residuos",
     pch = 19, col = "blue")
abline(h = 0, col = "red", lwd = 2)

# Graficar histograma de los residuos
hist(residuos,
     main = "Histograma de Residuos",
     xlab = "Residuos",
     col = "lightblue", border = "black")

# Graficar QQ-plot de los residuos
qqnorm(residuos, main = "QQ-Plot de los Residuos")
qqline(residuos, col = "red", lwd = 2) 

shapiro_test <- shapiro.test(residuos)
cat("Prueba de Shapiro-Wilk para normalidad de los residuos:\n")
print(shapiro_test)
```

Viendo esto se ve que los residuos no llegan a ser del todo normales, sin embargo, su variabilidad no está tán variada, ahora vamos a hacer la prueba de homocedaticidad.

```{r}
# Realizar la prueba de Breusch-Pagan para homocedasticidad
bptest_result <- bptest(model_log)
print(bptest_result)
```
Como podemos ver el p-valor a aumentado significativamente respecto al modelo original, pasando de un p-vamor muy pequeño a 0.8456, por lo que podemos decir que despues de esta transformación nuestras datos cumplen homocedasticidad diciendonos que la varianza de nuestros residuos presentan una variable constante.

## 6.2 Modelo no lineal multiple

Despues de elegir un modelo, vamos a ver el modelo no lienal multiple con los tres modelos anteriores, para ver como cambian y con cual de esos tre nos quedaríamos. Primero vamos a empezar con el modelo multiple que hemos realizado con la matriz de correlación.

```{r}
summary(modelo_multiple)
```

Ahora vamos a ver las distribuciones de cada una para ver que transformaciones se pueden hacer para mejorar el modelo.

```{r}
variables_seleccionadas <- select_(train, "Calories_Burned", "Session_Duration", "Fat_Percentage", "Water_Intake", "Experience_Level", "Avg_BPM", "Age")
pairs(variables_seleccionadas)
```


Este era el modelo que menos R2 tenía, sin embargo, hemos visto que los datos tienen bastante heterocedasticidad, por lo que vamos a aplicar la transformación logaritmica para nuestra variable objetivo.

```{r}
bc <- boxcox(modelo_multiple, lambda = seq(-2, 2, 0.1))
lambda_optimo_multiple <- bc$x[which.max(bc$y)]
```

```{r}
modelo_multiple_bc <- lm(((Calories_Burned^lambda_optimo_multiple - 1)/lambda_optimo_multiple) ~ Session_Duration + Fat_Percentage + Water_Intake + Experience_Level + Avg_BPM + Age, data = train)
summary(modelo_multiple_log)
```


Como vemos el R2 de este modelo aplicando la transformación se ha reducido, sin embargo, lo que buscamos es un modelo bueno, por lo que vamos a ver como son nuestros residuos y vamos a hacer la prueba de homocedasticidad para ver si ha mejorado algo nuestros residuos y el modelo.

```{r}
# Obtener los residuos
residuos_multiple_bc <- resid(modelo_multiple_bc)
valores_ajustados <- fitted(modelo_multiple_bc)

# Graficar residuos vs valores ajustados
plot(valores_ajustados, residuos_multiple_bc,
     main = "Residuos vs Valores Ajustados",
     xlab = "Valores Ajustados",
     ylab = "Residuos",
     pch = 19, col = "blue")
abline(h = 0, col = "red", lwd = 2)

```


```{r}
# Graficar histograma de los residuos
hist(residuos_multiple_bc,
     main = "Histograma de Residuos",
     xlab = "Residuos",
     col = "lightblue", border = "black")

```


```{r}
# Graficar QQ-plot de los residuos
qqnorm(residuos_multiple_bc, main = "QQ-Plot de los Residuos")
qqline(residuos_multiple_bc, col = "red", lwd = 2) 


```


```{r}
shapiro_test <- shapiro.test(residuos_multiple_bc)
print(shapiro_test)
```

```{r}
# Realizar la prueba de Breusch-Pagan para homocedasticidad
bptest_result <- bptest(residuos_multiple_bc)
print(bptest_result)
```

Despues de realizar varias transformaciones a distintas variables, como el logaritmo y la raiz a nuestra variable objetivo, así como el polinomio de orden 2 a Duracion de sesion y a porcentage graso, este el el modelo que mejor nos ha salido, en el como se puede ver, se ve que los residuos han mejorado, sin embargo, al hacer la prueba de homocedasticidad, vemos que incluso el p-valor ha disminuido. Ahora vamos a observar el modelo que se ha hecho mediante el metodo forward.

```{r}
summary(modelo_forward)
```

Primero de todo, vamos a ver la relación que se puede ver entre las variables.

```{r}
variables_seleccionadas <- select_(train, "Calories_Burned", "Session_Duration", "Avg_BPM", "Gender", "Age", "Resting_BPM")
pairs(variables_seleccionadas)
```


Vamos a realizar la raiz cuadrada de nuestra variable obejtivo para ver si al ver los residuos se ajustan mejor a la recta.

```{r}
modelo_forward_sqrt <- lm(sqrt(Calories_Burned) ~ Session_Duration + Avg_BPM + Gender + Age + Resting_BPM, data = train)
summary(modelo_forward_sqrt)
```

```{r}
# Obtener los residuos
residuos_forward_sqrt <- resid(modelo_forward_sqrt)
valores_ajustados <- fitted(modelo_forward_sqrt)

# Graficar residuos vs valores ajustados
plot(valores_ajustados, residuos_forward_sqrt,
     main = "Residuos vs Valores Ajustados",
     xlab = "Valores Ajustados",
     ylab = "Residuos",
     pch = 19, col = "blue")
abline(h = 0, col = "red", lwd = 2)

```


```{r}
# Graficar histograma de los residuos
hist(residuos_forward_sqrt,
     main = "Histograma de Residuos",
     xlab = "Residuos",
     col = "lightblue", border = "black")

```


```{r}
# Graficar QQ-plot de los residuos
qqnorm(residuos_forward_sqrt, main = "QQ-Plot de los Residuos")
qqline(residuos_forward_sqrt, col = "red", lwd = 2) 

```


```{r}
shapiro_test <- shapiro.test(residuos_forward_sqrt)
print(shapiro_test)
```

```{r}
# Realizar la prueba de Breusch-Pagan para homocedasticidad
bptest_result <- bptest(modelo_forward_sqrt)
print(bptest_result)
```
Como acabamos de comprobar, el hacer la raiz cuadrada el modelo del metodo forward, obtenemos más prediccion, pasando de un 0.979 a un 0.9812 además de eso al ver los residuos, vemos que tenemos unos valores atípocos a la izaquierda de la gráfica y que segun la prueba de shapiro-Wilk no podemos descartar que los residuos son normales, además tenemos que el p-valor de de la prueba de homocedasticidad nos da 0.72 quitandonos la heterocedasticidad que teniemos al hacer el modelo normal sin ninguna tranformación de variables.Ahora vamos a aplicar la transformación de boxcox para nuestra variable objetivo para ver si mejora a la transformación de la raiz. Primero buscamos el mejor lambda par nuestra transformación.

```{r}
bc_forward <- boxcox(modelo_forward, lambda = seq(-2, 2, 0.1))
lambda_optimo_forward <- bc_forward$x[which.max(bc_forward$y)]
```

```{r}
modelo_forward_bc <- lm(((Calories_Burned^lambda_optimo_forward - 1)/lambda_optimo_forward) ~ Session_Duration + Avg_BPM + Gender + Age + Resting_BPM, data = train)
summary(modelo_forward_bc)
```

```{r}
# Obtener los residuos
residuos_forward_bc <- resid(modelo_forward_bc)
valores_ajustados <- fitted(modelo_forward_bc)

# Graficar residuos vs valores ajustados
plot(valores_ajustados, residuos_forward_bc,
     main = "Residuos vs Valores Ajustados",
     xlab = "Valores Ajustados",
     ylab = "Residuos",
     pch = 19, col = "blue")
abline(h = 0, col = "red", lwd = 2)

```


```{r}
# Graficar histograma de los residuos
hist(residuos_forward_bc,
     main = "Histograma de Residuos",
     xlab = "Residuos",
     col = "lightblue", border = "black")

```


```{r}
# Graficar QQ-plot de los residuos
qqnorm(residuos_forward_bc, main = "QQ-Plot de los Residuos")
qqline(residuos_forward_bc, col = "red", lwd = 2) 

```


```{r}
shapiro_test <- shapiro.test(residuos_forward_bc)
print(shapiro_test)
```

```{r}
# Realizar la prueba de Breusch-Pagan para homocedasticidad
bptest_result <- bptest(modelo_forward_bc)
print(bptest_result)
```

Al hacer el modelo podemos ver como el R2 del modelo incluso ha aumentado hasta 0.982, dandonos un modelo que nos predice aun más. Mirando los residuos, vemos que al igual que con la raiz tenemos valores atípicos en la parte izquierda de la gráfica y ql mirar el qqplot, el extremo inferior es lo que más se separa de la recta, mientreas que la perte dentral y el extremo de la derecha se ajustanperfectamente, dandonos a entender que se podría ajustar a una normal, esto se nos confirma cuando al hacer la prueba de Shapiro-Wilk nos da un p-valor inferior a 0.05, por lo que no podemos descartar la normalidad de los residuos. Para terminar, al hacer la prueba de homocedasticidad, tenemos que p-valor es 0.266 lo cual es mayor a 0.05, por lo que tambien nos hemos quitado la heterocedasticidad con esta transformación de varable. Si nos tenemos que  quedar con alguna, sería la seguda, ya que es más precisa a la hora de predecir nuestra variable objetivo.

Para terminar, vamos a realizar un modelo no lineal con el modelo creado con el metodo stepwise.

```{r}
summary(modelo_stepwise)
```

Primero de todo, vamos a ver la relación que se puede ver entre las variables.

```{r}
variables_seleccionadas <- select_(train, "Calories_Burned", "Session_Duration", "Avg_BPM", "Gender", "Age", "Resting_BPM", "Weight", "Height", "BMI")
pairs(variables_seleccionadas)
```


Vamos a realizar la raiz cuadrada de nuestra variable obejtivo para ver si al ver los residuos se ajustan mejor a la recta.

```{r}
modelo_stepwise_sqrt <- lm(sqrt(Calories_Burned) ~ Session_Duration + Avg_BPM + Gender + Age + Resting_BPM + Weight + Height + BMI, data = train)
summary(modelo_stepwise_sqrt)
```

```{r}
# Obtener los residuos
residuos_stepwise_sqrt <- resid(modelo_stepwise_sqrt)
valores_ajustados <- fitted(modelo_stepwise_sqrt)

# Graficar residuos vs valores ajustados
plot(valores_ajustados, residuos_stepwise_sqrt,
     main = "Residuos vs Valores Ajustados",
     xlab = "Valores Ajustados",
     ylab = "Residuos",
     pch = 19, col = "blue")
abline(h = 0, col = "red", lwd = 2)

```


```{r}
# Graficar histograma de los residuos
hist(residuos_stepwise_sqrt,
     main = "Histograma de Residuos",
     xlab = "Residuos",
     col = "lightblue", border = "black")

```


```{r}
# Graficar QQ-plot de los residuos
qqnorm(residuos_stepwise_sqrt, main = "QQ-Plot de los Residuos")
qqline(residuos_stepwise_sqrt, col = "red", lwd = 2) 

```


```{r}
shapiro_test <- shapiro.test(residuos_stepwise_sqrt)
print(shapiro_test)
```

```{r}
# Realizar la prueba de Breusch-Pagan para homocedasticidad
bptest_result <- bptest(modelo_stepwise_sqrt)
print(bptest_result)
```

Como acabamos de comprobar, el hacer la raiz cuadrada el modelo del metodo forward, obtenemos más prediccion, pasando de un 0.979 a un 0.9812 además de eso al ver los residuos, vemos que tenemos unos valores atípocos a la izaquierda de la gráfica y que segun la prueba de shapiro-Wilk no podemos descartar que los residuos son normales, además tenemos que el p-valor de de la prueba de homocedasticidad nos da 0.72 quitandonos la heterocedasticidad que teniemos al hacer el modelo normal sin ninguna tranformación de variables.Ahora vamos a aplicar la transformación de boxcox para nuestra variable objetivo para ver si mejora a la transformación de la raiz. Primero buscamos el mejor lambda par nuestra transformación.

```{r}
bc_stepwise <- boxcox(modelo_stepwise, lambda = seq(-2, 2, 0.1))
lambda_optimo_stepwise <- bc_stepwise$x[which.max(bc_stepwise$y)]
```

```{r}
modelo_stepwise_bc <- lm(((Calories_Burned^lambda_optimo_stepwise - 1)/lambda_optimo_stepwise) ~ Session_Duration + Avg_BPM + Gender + Age + Resting_BPM + Weight + Height + BMI, data = train)
summary(modelo_stepwise_bc)
```

```{r}
# Obtener los residuos
residuos_stepwise_bc <- resid(modelo_stepwise_bc)
valores_ajustados <- fitted(modelo_stepwise_bc)

# Graficar residuos vs valores ajustados
plot(valores_ajustados, residuos_stepwise_bc,
     main = "Residuos vs Valores Ajustados",
     xlab = "Valores Ajustados",
     ylab = "Residuos",
     pch = 19, col = "blue")
abline(h = 0, col = "red", lwd = 2)

```


```{r}
# Graficar histograma de los residuos
hist(residuos_stepwise_bc,
     main = "Histograma de Residuos",
     xlab = "Residuos",
     col = "lightblue", border = "black")

```


```{r}
# Graficar QQ-plot de los residuos
qqnorm(residuos_stepwise_bc, main = "QQ-Plot de los Residuos")
qqline(residuos_stepwise_bc, col = "red", lwd = 2) 

```


```{r}
shapiro_test <- shapiro.test(residuos_stepwise_bc)
print(shapiro_test)
```

```{r}
# Realizar la prueba de Breusch-Pagan para homocedasticidad
bptest_result <- bptest(modelo_stepwise_bc)
print(bptest_result)
```

Teniendo ahora los modelos no lineales realizados con los distintos cambios de variables, podemos ver como con el modelo hecho con el método stepwise, al hacer la transformación de Box-Cox, vemos como el R2 del modelo aumenta hasta 0.983, lo que nos da el mayor ajuste de nuestra variable de todos los modelo, por otro lado, se ve como los residuos son más normales que en los otros dos modelos, además de eso el qqplot es bastante parecido al modelo anterior, y al hacer el test de Shapiro-Wilk, vemos como no podemos descartar la normalidad de los residuos. Por último vemos una mejora en el test de normalidad, sin embargo, comparado con el modelo con la transformación de la raiz, este tiene un p-valor menor, sin embargo es más preciso.

# 7. Conclusiones.
