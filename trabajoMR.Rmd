---
title: "gym_members"
author: "Nuria Oviedo, Aitana Garcia y Marcos López"
date: "2025-02-06"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# 0. Introducción

El conjunto de datos contiene un análisis de patrines de actividad física y rendimiento en distintos niveles de experiencia en gimnasios.

Estos datos se han extraido de [kaggle](https://www.kaggle.com/datasets/valakhorasani/gym-members-exercise-dataset). Segun la propia descripción de los datos,este conjunto de datos nos proporciona una descripción detallada de las turinad de ejercicio, los atributos físicos y las métricas de aptitud física de los miembros de gimnasios. En temas de salud es muy importante llevar un monitoreo de las cosas que hay que hacer para estar bien físicamente. El objetivo de este sistema es poder buscar patrones y evidencias de lo que tiene que hacer una persona para estar bien fisica y mentalmente. Este conjunto de dato nos da información sobre datos demográficos y niveles de experiencia, lo que permite un análisis integral de los patrones de aptitud física, la progresión de los atletas y las tendencias de salud. Además de esto no 

Según la descripción oficial de los datos, las variables que conforman el conjunto de datos son:

* Edad: Edad del miembro del gimnasio.
* Género: Género del miembro del gimnasio (masculino o femenino).
* Peso (kg): Peso del miembro en kilogramos.
* Altura (m): Altura del miembro en metros.
* Max_BPM: Frecuencia cardíaca máxima (pulsaciones por minuto) durante las sesiones de entrenamiento.
* Avg_BPM: Frecuencia cardíaca promedio durante las sesiones de entrenamiento.
* Resting_BPM: Frecuencia cardíaca en reposo antes del entrenamiento.
* Session_Duration (horas): Duración de cada sesión de entrenamiento en horas.
* Calorías_Quemadas: Total de calorías quemadas durante cada sesión.
* Workout_Type: Tipo de entrenamiento realizado (por ejemplo, Cardio, Fuerza, Yoga, HIIT).
* Fat_Percentage: Porcentaje de grasa corporal del miembro.
* Consumo_de_agua (litros): Ingesta diaria de agua durante los entrenamientos.
* Frecuencia_de_entrenamiento (días/semana): Número de sesiones de entrenamiento por semana.
* Nivel_Experiencia: Nivel de experiencia, desde principiante (1) hasta experto (3).
* IMC: Índice de Masa Corporal, calculado a partir de la altura y el peso.

Dado que es un problema de regresión, la variable objetivo (Cantidad de calorias quemadas durante la sesión de entrenamiento) es continua.


## Brain storming

1. Predicción de Calorías Quemadas
Objetivo: Modelar la cantidad de calorías quemadas en función de las variables disponibles.
Variables predictoras: Edad, Género, Peso, Altura, Max_BPM, Avg_BPM, Resting_BPM, Session_Duration, Workout_Type, Fat_Percentage, Water_Intake, Workout_Frequency, Experience_Level, BMI.

2. Clasificación del Tipo de Entrenamiento a partir de Variables Fisiológicas
Objetivo: Predecir el Workout_Type en función de variables como Max_BPM, Avg_BPM, Resting_BPM, Calories_Burned, Session_Duration y BMI.

3. Duracion de la sesión ideal 
Variables predictoras: Edad, Género, Peso, Altura, Max_BPM, Avg_BPM, Resting_BPM, Session_Duration, Workout_Type, Fat_Percentage, Workout_Frequency, Experience_Level, BMI.

4. Impacto del Nivel de Hidratación en el Rendimiento
Objetivo: Analizar cómo el Water_Intake afecta variables como Max_BPM, Avg_BPM, Calories_Burned o Session_Duration.


Decidimos trabajar en las ideas 1 y 4.

## Cargar paquetes necesarios

```{r}

library(ggplot2)
library(car) # pruebas de diagnóstico
library(lmtest) # prueba de homocedasticidad
library(dplyr) # manipulación de datos
library(GGally) # visualización avanzad
library(HistData) # datos históricos de Galton
library(gridExtra) # organizar múltiples gráficos
library(caret)
library(corrplot)
library(MASS) 
library(tidyverse)
library(minpack.lm)
```


# 1. Data undestandig

## Cargamos los datos.
```{r}
datos <- read.csv("gym_members_exercise_tracking.csv")
```
```{r include=FALSE}
datos <- datos %>% 
  rename(Weight = Weight..kg., 
         Height = Height..m., 
         Session_Duration = Session_Duration..hours., 
         Water_Intake = Water_Intake..liters., 
         Workout_Frequency = Workout_Frequency..days.week.)
```

## Tamaño del dataset.
```{r}
size <- dim(datos)
```

En estos datos podemos ver que tenemos un total de `r size[1]` observaciones y `r size [2]` variables en este dataset.

## Variables.
```{r}
str(datos)
```

Al ver esto podemos ver que estos datos son en su mayoría de tipo numérico o entero, sin embargo, tenemos dos variables de tipo cadena de caracteres (`char`), `Gender` y `Workout_Type`.

## Valores faltantes.
```{r}
sum(is.na(datos))
```

Vemos que no tenemos ningun datos faltante o missing entre nuestros datos.

## Primer vistazo a los datos.
```{r}
head(datos, 5)
```
Realizamos la partición de nuestros datos.

```{r}
# Ponemos una semilla para que la partición sea siempre la misma
set.seed(1)

# Buscamos los indices para la parte de train y de test y val
indices_train <- createDataPartition(datos$Calories_Burned, p = 0.7, list = FALSE)

# Creamos la variable train y test_val
train <- datos[indices_train, ]
test_val <- datos[-indices_train, ]

# Buscamos los indices para test
indices_test <- createDataPartition(test_val$Calories_Burned, p = 0.5, list = FALSE)

# Creamos la variabe test y val
test <- test_val[indices_test, ]
val <- test_val[-indices_test, ]
```

Miramos la información de nuestros datos de entrenamiento

```{r}
dim(train)
head(train)
str(train)
```

# 2. EDA

Antes de nada vamos a ver información de nuestra variable objetivo importante
```{r}
summary(train$Calories_Burned)
```
Con esto nos da una idea de la cantidad de calorias que las personas pueden quemar, vemos como la media es casi 900 kcalorias y vemos tambien que el mínimo es de unas 300 kcal y el máximo es de 1700 kcal. 

Vamos a ver la forma de nuestra variable objetivo gráficamente.
```{r}
train |> ggplot(mapping = aes(x = Calories_Burned)) +
  geom_histogram(bins = 30) +
  theme_bw()
```

Viendo este histograma se puede ver como las calorias quemadas se acerca a una distribución normal, viendo los datos de antes, se ve que este histograma si que tiene sentido. 


## Distribucion de Calories_burned por genero

```{r}
train |> ggplot(aes(x = Gender, y = Calories_Burned, fill = Gender)) +
  geom_boxplot() +
  labs(title = "Distribución de Calorías Quemadas por Género",
       x = "Género", y = "Calorías Quemadas") +
  theme_minimal()

```

Este gráfico permite analizar si hay diferencias significativas en las calorías quemadas entre hombres y mujeres, podemos observar que la media de calorías quemadas en hombres es ligeramente mayor aunque no hay una diferencia significativa.

## Relación entre Calories_Burned y Session_Duration

```{r}
train |> ggplot(aes(x = Session_Duration, y = Calories_Burned)) +
  geom_point(alpha = 0.5, color = "blue") +
  geom_smooth(method = "lm", color = "red") +
  labs(title = "Relación entre Duración del Entrenamiento y Calorías Quemadas",
       x = "Duración del Entrenamiento (horas)", y = "Calorías Quemadas") +
  theme_minimal()

```
Podemos ver que hay una tendencia clara entre el tiempo de entrenamiento y las calorías quemadas

## Impacto del Nivel de Hidratación en el Rendimiento

### Relación entre Water_Intake y Calories_Burned

```{r}
train |> ggplot(aes(x = Water_Intake, y = Calories_Burned)) +
  geom_point(alpha = 0.5, color = "blue") +
  geom_smooth(method = "lm", color = "red") +
  labs(title = "Relación entre Ingesta de Agua y Calorías Quemadas",
       x = "Consumo de Agua (litros)", y = "Calorías Quemadas") +
  theme_minimal()

```
Podemeos observar una tendencia positiva en la que mayor hidratación esté asociada con un mayor gasto calórico.


### Relación entre Water_Intake y Max_BPM / Avg_BPM

```{r}
train |> ggplot(aes(x = Water_Intake, y = Max_BPM)) +
  geom_point(alpha = 0.5, color = "blue") +
  geom_smooth(method = "lm", color = "red") +
  labs(title = "Relación entre Ingesta de Agua y Frecuencia Cardíaca Máxima",
       x = "Consumo de Agua (litros)", y = "Max BPM") +
  theme_minimal()

train |> ggplot(aes(x = Water_Intake, y = Avg_BPM)) +
  geom_point(alpha = 0.5, color = "blue") +
  geom_smooth(method = "lm", color = "red") +
  labs(title = "Relación entre Ingesta de Agua y Frecuencia Cardíaca Promedio",
       x = "Consumo de Agua (litros)", y = "Avg BPM") +
  theme_minimal()

```
Por lo que se observa en la imagen, la relación entre la ingesta de agua y la frecuencia cardíaca máxima (Max BPM) es prácticamente inexistente. La línea de tendencia roja es casi horizontal, lo que indica una correlación muy baja o nula entre estas variables.

### Comparación del rendimiento cardíaco según niveles de hidratación

```{r}
train %>%
  mutate(Water_Intake_Level = case_when(
    Water_Intake < 2 ~ "Baja",
    Water_Intake >= 2 & Water_Intake < 3 ~ "Media",
    Water_Intake >= 3 ~ "Alta"
  )) %>%
  ggplot(aes(x = Water_Intake_Level, y = Avg_BPM, fill = Water_Intake_Level)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Frecuencia Cardíaca Promedio según Consumo de Agua",
       x = "Nivel de Ingesta de Agua",
       y = "Frecuencia Cardíaca Promedio (BPM)") +
  theme_minimal() +
  scale_fill_manual(values = c("red", "yellow", "green"))

```

```{r}
cor.test(train$Water_Intake, train$Avg_BPM)

```
El resultado del test de correlación de Pearson indica que no hay una relación significativa entre el consumo de agua y la frecuencia cardíaca promedio (Avg_BPM):

Coeficiente de correlación (r): 0.0067 → Casi nula, lo que sugiere que no hay una asociación lineal entre ambas variables.
p-valor: 0.8608 → Muy alto, lo que significa que no podemos rechazar la hipótesis nula (es decir, no hay evidencia estadística de una relación).
Intervalo de confianza al 95%: [-0.068, 0.081] → Incluye el 0, reforzando que la relación es débil o inexistente.


```{r}
ggplot(train, aes(x = Water_Intake, y = Session_Duration)) +
  geom_point(color = "blue", alpha = 0.5) +
  geom_smooth(method = "lm", color = "red", se = TRUE) +
  labs(title = "Relación entre Ingesta de Agua y Duración del Entrenamiento",
       x = "Consumo de Agua (litros)", 
       y = "Duración del Entrenamiento (horas)") +
  theme_minimal()

```
Observamos una pendiente positiva, indicando que las personas más hidratadas entrenan por más tiempo.

### Correlación entre Consumo de Agua y Duración del Entrenamiento

```{r}
cor.test(train$Water_Intake, train$Session_Duration)

```
Relación entre Consumo de Agua y Duración del Entrenamiento

Correlación: 0.246 (moderada)
p-valor: 6.23e-11 (muy significativo)

 Hay una relación positiva y significativa entre la ingesta de agua y la duración del entrenamiento. Esto sugiere que las personas que se hidratan más tienden a entrenar por más tiempo.


### Correlación entre Consumo de Agua y Calorías Quemadas

```{r}
cor.test(train$Water_Intake, train$Calories_Burned)

```

Correlación: 0.330 (moderada)
p-valor: < 2.2e-16 (extremadamente significativo)

Existe una relación clara entre la hidratación y la cantidad de calorías quemadas. Esto indica que una mayor ingesta de agua podría estar asociada con un mayor gasto energético durante el ejercicio.




# 3. Modelización estadística.
Nuestro problema para analizar es ver si hay alguna relación positiva entre las calorias que quema una persona por duración del entrenamineto, con esto buscamos como objetivo determinar si cuanto más tiempo una persona entrene, más kcalorias quema durante el entrenamiento. 

Las variables que se involucran seria el tiempo de duración de las sesiones de entrenamiento (variable explicativa) y la cantidad de calorias que quema una persona (variable respuesta).

Miramos los datos de la variable explicativa

```{r}
summary(train$Session_Duration)
```

Podemos ver que las personas entrenan una media de 1.256 horas, lo que hace 1 hora y 15 minutos, además podemos ver que dentro de los datos registrados, el mínimo de horas que se ha almacenado es de 0.5 horas y el máximo es de 2 horas.

Observamos los datos de esas dos variables.

```{r}

```


Viendo esta cabecera, se puede ver a simple vista que si que puede haber una realción entre la duración de el entrenamiento con las calorias que se queman, para verlo más claro, representamos ambas variables graficamente.

```{r}
train |>
  ggplot(mapping = aes(x = Calories_Burned, y = Session_Duration)) +
  geom_point()
```

Dado que tenemos una relación positiva entre estas dos variables, voy a proponer un modelso para relacionar estas dos variables., buscamos mediante el método de mínimos cuadrados hallar los valores de $\beta_0$ y $\beta_1$ para poder llegar a un modelo con la forma: $\text{Calorias} = \beta_0 + \beta_1 \text{(Tiempo de entrenamient0)} + \epsilon$.

```{r}
# Creamos el modelo lineal y lo analizamos
model <- lm(Calories_Burned ~ Session_Duration, data = train)
summary(model)
```
observamos que el valor del intercepto es de 5,659 aunque midiendo el tiempo en horas no es muy relevante que con o horas entrenadas quemes 5,659

la pendiente tiene unvalor de 714.1 es decir por cada hora extra a la sesión de entrenamiento se queman 714.1 calorías más en promedio

al tener un p value < 2.2e^-16 podemos afirmar que la duración es altamente significativo

observamos que R^2 es 0.8114 un ajuste bastante bueno

Error estándar de los residuos = 116: En promedio, las predicciones de nuestro modelo tienen un error de ±116 calorías.

Ahora vamos a ver el modelo gráficamente.

```{r}
train |> 
  ggplot(mapping = aes(x = Calories_Burned, y = Session_Duration)) +
  geom_point() +
  geom_smooth(method = "lm", col = "red") +
  labs(title = "Relación entre calorias quemadas y la duración de la sesion.",
       x = "Calorias quemadas.",
       y = "Duración de la sesion.") +
  annotate("text", x = 500, y = 2.0, label = paste("y =", round(coef(model)[1], 2), "+", round(coef(model)[2], 2), "x"), color = "red")
```

La linea nos muestra una relación alcista segun las calorias quemadas y el tiempo de entrenamiento. Que el valor de $\beta_0$ sea menor a 0 no nos importa mucho, debido a que el mínimo es 0.5 (media hora) por lo que nunca va a ser negarivo ya que $\beta_1$ es 721.79 

## Correlación

Vamos a calcular y entender la correlación entre las variables de nuestro estudio.

```{r}
# Cogemos solo las variables numéricas para hacer matrices de correlación
train_num <- select_if(train, is.numeric)

# Matriz de correlación de variables cuantitativas.
m <- cor(train_num, use = "complete.obs")
corrplot(m,type = "upper", method="number")
```

## Covarianza
```{r}
calorias <- train$Calories_Burned
sesion <- train$Session_Duration

covarianza <- round(cov(calorias, sesion), 3)

print(paste("La covarianza entre la calorias quemadas por la sesion de entrenamiento es: ", covarianza))
```

Con esta covarianza podemos observar que ambas variables aumentan juntas, además de que no es cercana a 0 por lo que entre estas variables hay una relación lineal entre las variables.

## Coeficiente de correlación de lineal.
Calculamos y mostramos el coeficiente de correlación de Pearson entre la duración de las sesiones de ejercicio y las calorías quemadas.

```{r}
correlacion_pearson <- cor(train$Session_Duration, train$Calories_Burned, use = "complete.obs")
cat("El coeficiente de correlación de Pearson entre la duración de la sesión y las calorías quemadas es:", round(correlacion_pearson, 8), "\n")
```

La correlación de Pearson nos confirma lo que habiamos visto calculando la covarianza, como es cercano a 1, existe una relación lineal fuerte entre las variables y como es positivo, las variables aumentan a la par.
## Tabla ANOVA
tras realizar el analísis de la tabla de varianza (ANOVA) podemos concluir que los factores más influyentes son 
la duración de la sesión, el average BPM, el género y el año. Luego encontramos factores influyentes pero en menor medida como el BMI y la altura. El resto de factores no son influyentes en la quema de calorías
```{r}
# Ajustar el modelo de regresión lineal
modelo <- lm(Calories_Burned ~ Age + Gender  + Height+ Weight + Max_BPM + Avg_BPM + Resting_BPM + Session_Duration+ Calories_Burned + Workout_Type + Fat_Percentage + Water_Intake + Workout_Frequency + Experience_Level + BMI , data = train)

# Obtener la tabla ANOVA
tabla_anova <- anova(modelo)
cat("Tabla ANOVA:\n")
#mostrar tabla anova
print(tabla_anova)
```


## 3.1 Análisis de Residuos

Realizamos el análisis de residuos para evaluar el modelo ajustado.

### Residuos vs Valores Ajustados

```{r}
# Obtener los residuos
residuos <- resid(model)
valores_ajustados <- fitted(model)

# Graficar residuos vs valores ajustados
plot(valores_ajustados, residuos,
     main = "Residuos vs Valores Ajustados",
     xlab = "Valores Ajustados",
     ylab = "Residuos",
     pch = 19, col = "blue")
abline(h = 0, col = "red", lwd = 2)

```
Podemos observar que los residuos se distribuyen de manera aleatoria alrededor del eje, sin mostrar patrones claros, poor lo que el supuesto de linealidad se cumple. 



### Histograma de los Residuos
```{r}
# Graficar histograma de los residuos
hist(residuos,
     main = "Histograma de Residuos",
     xlab = "Residuos",
     col = "lightblue", border = "black")

```
Podemos observar que nuestra distribución se acerca a una distribucion noral con un ligero desplazamiento a la izquierda. 



### QQ-Plot de los Residuos


```{r}

# Graficar QQ-plot de los residuos
qqnorm(residuos, main = "QQ-Plot de los Residuos")
qqline(residuos, col = "red", lwd = 2) 

```
podemos observar que los puntos se alinean con la linea roja diagonal, por lo que podemos deducir que siguen una distribucion normal y concuerda con lo esperado.



### Prueba de Normalidad de los Residuos (Shapiro-Wilk)

```{r}
# Realizar la prueba de Shapiro-Wilk para normalidad de los residuos

shapiro_test <- shapiro.test(residuos)
cat("Prueba de Shapiro-Wilk para normalidad de los residuos:\n")
print(shapiro_test)

```
Observamos que el p-valor obtenido es menor que 0.05, por lo que rechazaríamos la Hipótesis nula.





## 3.2 Diagnóstico del Modelo: Pruebas de Homocedasticidad y Leverage

### Prueba de Homocedasticidad (Breusch-Pagan)

```{r}
# Realizar la prueba de Breusch-Pagan para homocedasticidad
bptest_result <- bptest(model)
cat("\nPrueba de Breusch-Pagan para homocedasticidad:\n")
print(bptest_result)

```
La prueba de Breusch-Pagan muestra un valor p muy pequeño (< 2.2e-16), lo que indica que hay heterocedasticidad en el modelo. Esto significa que los errores del modelo no tienen una varianza constante, lo que puede afectar la precisión de los resultados. En términos más simples, la relación entre las variables puede cambiar dependiendo de ciertos factores, como la experiencia en el gimnasio o características físicas de los usuarios. Para corregir esto, se pueden hacer algunos ajustes, como transformar los datos, usar otro tipo de regresión o aplicar correcciones estadísticas para mejorar la fiabilidad del análisis.


### Análisis de Leverage 

Calculamos el leverage de las observaciones y graficamos las observaciones con leverage alto.

```{r}
# Calcular leverage
leverage <- hatvalues(model)

# Umbral para leverage alto
n <- nrow(train)
p <- length(coef(train))  # Número de parámetros (incluyendo el intercepto)
leverage_threshold <- 2 * p / n

# Identificar observaciones con leverage alto
leverage_high <- which(leverage > leverage_threshold)

cat("\nUmbral para leverage alto:", leverage_threshold, "\n")
cat("\nObservaciones con leverage alto (si las hay):\n")
print(leverage_high)

# Gráfico de leverage
grafico_leverage <- ggplot(data.frame(leverage), aes(x = seq_along(leverage), y = leverage)) +
  geom_point(color = "blue") +
  geom_hline(yintercept = leverage_threshold, col = "red", lwd = 2, lty = 2) +
  labs(title = "Leverage de las Observaciones", x = "Índice de Observación", y = "Leverage")

# Mostrar gráfico
grafico_leverage
```

El gráfico de leverage muestra la influencia de cada observación en los coeficientes del modelo. Observaciones con leverage alto (por encima del umbral) tienen un gran efecto en el ajuste del modelo.
El gráfico de leverage muestra que la mayoría de las observaciones tienen un leverage bajo, lo que indica que no influyen demasiado en el ajuste del modelo. Sin embargo, hay una dispersión uniforme de puntos a ambos lados de la línea roja discontinua en niveles más altos de leverage. Esto sugiere que algunas observaciones tienen un mayor impacto en los coeficientes del modelo y podrían ser casos atípicos o influyentes. Es importante analizar estos puntos para determinar si afectan negativamente la estabilidad del modelo y, si es necesario, considerar ajustes o métodos robustos.


### Análisis de la Distancia de Cook

 mide la influencia de cada observación sobre los coeficientes del modelo.

```{r}
# Calcular Distancia de Cook
cooks_distance <- cooks.distance(model)

# Gráfico de Distancia de Cook
grafico_cooks_distance <- ggplot(data.frame(cooks_distance), aes(x = seq_along(cooks_distance), y = cooks_distance)) +
  geom_point(color = "blue") +
  geom_hline(yintercept = 4 / n, col = "red", lwd = 2, lty = 2) +
  labs(title = "Distancia de Cook", x = "Índice de Observación", y = "Distancia de Cook")

# Mostrar gráfico
grafico_cooks_distance

```

La distancia de Cook mide la influencia de cada observación sobre los coeficientes del modelo. Observaciones con una distancia de Cook alta (por encima del umbral) pueden ser altamente influyentes. En el gráfico, hay algunas observaciones con distancia de Cook alta, lo que indica que estas observaciones pueden estar afectando de manera desproporcionada el ajuste del modelo
Podemos observar que la mayoría de las observaciones tienen una influencia baja en el modelo, ya que están acumuladas en la parte inferior, cerca de la línea roja. Sin embargo, hay algunas observaciones con una distancia de Cook alta, lo que indica que pueden estar afectando de manera significativa el ajuste del modelo. Estos puntos atípicos podrían estar influyendo de manera desproporcionada en los coeficientes, por lo que sería recomendable revisarlos para determinar si representan datos válidos o si es necesario aplicar ajustes para mejorar la estabilidad del modelo.

## 3.3 Análisis de DFFITS

mide el cambio en los valores ajustados cuando se omite una observación.

```{r}
# Calcular DFFITS
dffits_values <- dffits(model)

# Gráfico de DFFITS
grafico_dffits <- ggplot(data.frame(dffits_values), aes(x = seq_along(dffits_values), y = dffits_values)) +
  geom_point(color = "green") +
  geom_hline(yintercept = c(2 * sqrt(length(coef(model)) / n)), col = "red", lwd = 2, lty = 2) +
  labs(title = "DFFITS", x = "Índice de Observación", y = "DFFITS")

# Mostrar gráfico
grafico_dffits

```

El gráfico de DFFITS muestra que la mayoría de las observaciones tienen poca influencia en el modelo, ya que están acumuladas alrededor de cero y dentro del rango de ±0.1, sin sobrepasar la línea roja. Sin embargo, hay algunas observaciones que superan este umbral, lo que indica que pueden estar afectando significativamente los valores ajustados. Estas observaciones deberían revisarse para determinar si representan datos válidos o si están distorsionando el modelo, ya que podrían influir en la precisión de las predicciones


## 3.4 Análisis de DFBETAS

nos indican la influencia de cada observación sobre cada coeficiente de la regresión.


```{r}
# Calcular DFBETAS# Calcular DFBETAS
dfbetas_values <- dfbetas(model)

# Convertir dfbetas_values a un data.frame para poder usarlo en ggplot
dfbetas_df <- as.data.frame(dfbetas_values)

# Graficar DFBETAS para el coeficiente de la pendiente (segunda columna si existe)
grafico_dfbetas <- ggplot(dfbetas_df, aes(x = seq_along(dfbetas_df[,2]), y = dfbetas_df[,2])) + # Usamos el coeficiente de la pendiente
  geom_point(color = "purple") +
  geom_hline(yintercept = 2 / sqrt(n), col = "red", lwd = 2, lty = 2) +
  labs(title = "DFBETAS para el Coeficiente de la Pendiente", x = "Índice de Observación", y = "DFBETAS")

# Mostrar gráfico
grafico_dfbetas


```
El gráfico de DFBETAS muestra que la mayoría de las observaciones tienen poca influencia en los coeficientes del modelo, ya que están acumuladas alrededor de cero y dentro del rango de ±0.1, sin sobrepasar la línea roja. Sin embargo, algunas observaciones superan este umbral, lo que indica que pueden estar afectando de manera significativa los coeficientes de regresión. Es importante revisar estos puntos para determinar si están influyendo de manera desproporcionada en el modelo y, si es necesario, considerar ajustes para mejorar su estabilidad.


# Modelo de regresión lineal multiple.

```{r}

# Ajustar modelo de regresión lineal múltiple
modelo <- lm(Calories_Burned ~ Age + Gender + Weight + Height + Max_BPM + 
             Avg_BPM + Resting_BPM + Session_Duration + BMI + 
             Workout_Type + Fat_Percentage + Water_Intake + 
             Workout_Frequency + Experience_Level, data = train)

# Resumen del modelo
summary(modelo)

```
El modelo de regresión lineal múltiple presenta un **ajuste muy fuerte** con un \( R^2 \) de **0.9851**, lo que indica que el 98.51% de la variabilidad en el **BMI** puede explicarse por las variables independientes incluidas. Variables como **peso (p < 0.001)**, **altura (p < 0.001)**, **género (p < 0.001)**, **edad (p = 0.00215)** y **calorías quemadas (p = 0.01446)** son estadísticamente significativas, lo que sugiere que tienen un impacto importante en el BMI. En contraste, variables como **frecuencia de entrenamiento, nivel de experiencia y consumo de agua** no muestran una relación estadísticamente significativa con el BMI. Además, los residuos parecen estar bien distribuidos, lo que respalda la validez del modelo. Sin embargo, la relación negativa con la **duración de la sesión de ejercicio** y la no significancia de la **frecuencia de entrenamiento** pueden indicar la necesidad de revisar la influencia de estos factores en la predicción del BMI.


###  Interpretación de los Resultados

Los coeficientes estimados indican la relación entre cada variable independiente y el BMI:

Variables con valores p < 0.05 tienen un impacto significativo.
R² y R² ajustado indican cuánto del BMI puede explicarse por el modelo.

```{r}
# Extraer coeficientes y p-valores
coeficientes <- summary(modelo)$coefficients
coeficientes

```
gresión lineal múltiple indican que las variables como el peso, altura, género, edad y calorías quemadas tienen un impacto significativo sobre el BMI, lo que sugiere que estas son las variables más relevantes para predecir el índice de masa corporal. En cambio, otras variables como el nivel de experiencia, frecuencia de entrenamiento, porcentaje de grasa corporal y tipo de ejercicio no muestran una relación estadísticamente significativa en este contexto.

El R² alto (0.9851) y la baja desviación estándar de los residuos sugieren que el modelo tiene un buen ajuste, pero la falta de significancia de algunas variables podría implicar que estas tienen un efecto indirecto sobre el BMI o que se requieren transformaciones adicionales del modelo. Este análisis resalta la importancia de los factores físicos y metabólicos en la predicción del BMI, pero también sugiere que un análisis más detallado y ajustes en las variables podrían mejorar la precisión del modelo.


## Diagnóstico del Modelo

Analizamos los residuos y verificamos la validez de los supuestos del modelo.

```{r}
# Gráfico de residuos vs valores ajustados
ggplot(data = train, aes(x = fitted(modelo), y = residuals(modelo))) +
  geom_point() +
  geom_hline(yintercept = 0, col = "red") +
  labs(title = "Residuos vs Valores Ajustados", x = "Valores Ajustados", y = "Residuos")

# Histograma de residuos para evaluar normalidad
ggplot(data.frame(residuales = residuals(modelo)), aes(x = residuales)) +
  geom_histogram(bins = 20, fill = "blue", alpha = 0.7) +
  labs(title = "Distribución de los Residuos", x = "Residuos", y = "Frecuencia")
# Gráfico de residuos vs valores ajustados
ggplot(data = train, aes(x = fitted(modelo), y = residuals(modelo))) +
  geom_point() +
  geom_hline(yintercept = 0, col = "red") +
  labs(title = "Residuos vs Valores Ajustados", x = "Valores Ajustados", y = "Residuos")

# Histograma de residuos para evaluar normalidad
ggplot(data.frame(residuales = residuals(modelo)), aes(x = residuales)) +
  geom_histogram(bins = 20, fill = "blue", alpha = 0.7) +
  labs(title = "Distribución de los Residuos", x = "Residuos", y = "Frecuencia")

```
El análisis de los residuos muestra que estos siguen una distribución aproximadamente normal, lo cual se confirma con el histograma que no presenta colas largas ni desplazamientos significativos. Esto sugiere que no hay grandes violaciones de los supuestos de normalidad, lo que respalda la validez del modelo. Además, el gráfico de residuos vs valores ajustados El gráfico de residuos vs valores ajustados muestra una forma que sugiere una ligera tendencia en los residuos, especialmente cerca de los valores de x=25 y y=0 (línea roja). Aunque la mayoría de los residuos están dispersos de manera aleatoria alrededor de la línea cero, esta leve concentración en una zona particular podría indicar la presencia de heterocedasticidad, es decir, que la varianza de los residuos no es constante en todo el rango de valores ajustados. Este patrón podría sugerir que el modelo no captura completamente ciertos aspectos de los datos en esos puntos específicos. A pesar de esto, la distribución general de los residuos es adecuada, lo que indica que el modelo es relativamente bueno, aunque se podrían considerar transformaciones o la inclusión de nuevas variables para mejorar su precisión en las áreas donde se observa esta ligera tendencia. 


# 4. Seleccion de variables

Método Forward

```{r}
# Modelo vacío (sin variables)
modelo_vacio <- lm(Calories_Burned ~ 1, data = train)

# Selección hacia adelante (Forward Selection)
modelo_forward <- step(modelo_vacio, 
                       scope = ~ Age + Gender + Weight + Height +Max_BPM+ Avg_BPM + Resting_BPM + 
                                Session_Duration + Workout_Type +Fat_Percentage +Water_Intake + BMI + Workout_Frequency+ Experience_Level, 
                       direction = "forward")

# Ver resumen del modelo seleccionado
summary(modelo_forward)

```

El modelo final tras usar el método forward incluye las siguientes variables: Session_Duration, Avg_BPM, Gender, Age, Resting_BPM, y Workout_Type

Resultados:
R²: 0.979 esto indica que el modelo explica aproximadamente el 97.9% de la variabilidad en las calorías quemadas.
AIC: 5025.39, que es un valor bastante bajo, lo que sugiere un buen ajuste del modelo.
Coeficientes:
Session_Duration tiene un coeficiente positivo y significativo, lo que indica que a mayor duración de la sesión, mayor cantidad de calorías quemadas.
Avg_BPM y Gender también son muy significativos, tienen bastante impacto en la cantidad de calorías quemadas.
Age tiene un coeficiente negativo, lo que sugiere que, a medida que la edad aumenta, las calorías quemadas tienden a disminuir, aunque en una magnitud pequeña.
Resting_BPM tiene un coeficiente positivo, indicando que a mayor BPM en reposo, mayor número de calorías quemadas.
Workout_Type tiene un coeficiente negativo, pero no es muy diferente de cero (p > 0.05), lo que puede indicar que no es una variable determinante en este caso.

Método Backward

```{r}
# Ajustamos el modelo inicial con todas las variables
modelo_inicial <- lm(Calories_Burned ~ Age + Gender + Weight + Height +Max_BPM+ Avg_BPM + Resting_BPM + 
                                Session_Duration + Workout_Type +Fat_Percentage +Water_Intake + BMI + Workout_Frequency+ Experience_Level,  data = train)

# Aplicamos el método backward para la eliminación de variables
modelo_backward <- step(modelo_inicial, direction = "backward", trace = 1)

# Mostrar resumen del modelo final después de la selección
summary(modelo_backward)


```

Método Stepwise

```{r}

# Modelo completo: Usamos todas las variables
modelo_completo <- lm(Calories_Burned ~ ., data = train)

# Aplicar el método Stepwise (tanto Forward como Backward)
modelo_stepwise <- step(modelo_completo, direction = "both", trace = 1)

# Ver el resumen del modelo ajustado
summary(modelo_stepwise)



```

El modelo tiene un R² de 0.9792, lo que indica que explica el 97.92% de la variabilidad en las calorías quemadas, lo cual podemos considerar un buen ajuste. El error residual estándar es de 39.12, por tanto las predicciones del modelo tienen un error promedio de 39.12 calorías. El estadístico F es 3523 con un p-valor muy bajo lo que indica que el modelo en su conjunto es altamente significativo. Se han eliminado variables como Max_BPM, Water_Intake, Fat_Percentage y Experience_Level, al no mejorar el ajuste del modelo. Las variables más influyentes son Age, Gender, Avg_BPM y Session_Duration, con un impacto directo en las calorías quemadas.

método lasso

```{r}
# Instalar paquete si no está instalado
if (!require(glmnet)) install.packages("glmnet", dependencies = TRUE)

# Cargar librería
library(glmnet)

train$Gender <- as.numeric(as.factor(train$Gender))
train$Workout_Type <- as.numeric(as.factor(train$Workout_Type))

# ---- 1. Preparar los datos ----
# Separar variables predictoras (X) y la variable objetivo (y)
X <- as.matrix(train[, -which(names(train) == "Calories_Burned")])  # Matriz de predictores
y <- train$Calories_Burned  # Variable objetivo

# ---- 2. Ajustar modelo Lasso ----
set.seed(123)  # Fijar semilla para reproducibilidad
modelo_lasso <- cv.glmnet(X, y, alpha = 1,  # Lasso (alpha = 1)
                          nfolds = 10,  # Validación cruzada 10-fold
                          type.measure = "mse")  # Minimizar el error cuadrático medio

# ---- 3. Obtener la mejor lambda ----
lambda_opt <- modelo_lasso$lambda.min
cat("Mejor lambda:", lambda_opt, "\n")

# ---- 4. Hacer predicciones ----
y_pred <- predict(modelo_lasso, s = lambda_opt, newx = X)

# ---- 5. Evaluación del modelo ----
mse <- mean((y - y_pred)^2)  # Error cuadrático medio
rmse <- sqrt(mse)  # Raíz del error cuadrático medio
r2 <- cor(y, y_pred)^2  # Coeficiente de determinación

cat("MSE:", mse, "\n")
cat("RMSE:", rmse, "\n")
cat("R²:", r2, "\n")

# ---- 6. Ver coeficientes seleccionados por Lasso ----
coeficientes <- coef(modelo_lasso, s = lambda_opt)
print(coeficientes)


```

Ridge

```{r}
# Preparar los datos
# Crear la matriz de características X (sin la variable dependiente)
X <- as.matrix(train[, -which(names(train) == "Calories_Burned")])

# Crear el vector de la variable dependiente Y
y <- train$Calories_Burned

# Ajustar el modelo Ridge con validación cruzada (alpha = 0)
modelo_ridge <- cv.glmnet(X, y, alpha = 0)

# Ver el valor óptimo de lambda
cat("Mejor lambda:", modelo_ridge$lambda.min, "\n")

# Resumen del modelo
summary(modelo_ridge)

# Graficar la curva de validación cruzada
plot(modelo_ridge)

# Hacer predicciones con el valor óptimo de lambda
y_pred_ridge <- predict(modelo_ridge, s = "lambda.min", newx = X)

# Calcular el MSE (Error Cuadrático Medio)
mse_ridge <- mean((y - y_pred_ridge)^2)
cat("MSE del modelo Ridge:", mse_ridge, "\n")

# Calcular el RMSE (Raíz del Error Cuadrático Medio)
rmse_ridge <- sqrt(mse_ridge)
cat("RMSE del modelo Ridge:", rmse_ridge, "\n")

# Calcular el R² (Coeficiente de Determinación)
r2_ridge <- 1 - sum((y - y_pred_ridge)^2) / sum((y - mean(y))^2)
cat("R² del modelo Ridge:", r2_ridge, "\n")
```

elastic_net
 
```{r}
# Cargar la librería glmnet
library(glmnet)

# Preparar los datos
X <- as.matrix(train[, -which(names(train) == "Calories_Burned")])
y <- train$Calories_Burned

# Ajustar el modelo Elastic Net
# alpha = 0.5 es una mezcla equilibrada entre Ridge y Lasso
modelo_elastic_net <- cv.glmnet(X, y, alpha = 0.5)

# Ver el mejor valor de lambda
cat("Mejor lambda para Elastic Net:", modelo_elastic_net$lambda.min, "\n")

# Resumen del modelo
summary(modelo_elastic_net)

# Hacer predicciones con el valor óptimo de lambda
y_pred_elastic_net <- predict(modelo_elastic_net, s = "lambda.min", newx = X)

# Calcular el MSE (Error Cuadrático Medio)
mse_elastic_net <- mean((y - y_pred_elastic_net)^2)
cat("MSE del modelo Elastic Net:", mse_elastic_net, "\n")

# Calcular el RMSE (Raíz del Error Cuadrático Medio)
rmse_elastic_net <- sqrt(mse_elastic_net)
cat("RMSE del modelo Elastic Net:", rmse_elastic_net, "\n")

# Calcular el R² (Coeficiente de Determinación)
r2_elastic_net <- 1 - sum((y - y_pred_elastic_net)^2) / sum((y - mean(y))^2)
cat("R² del modelo Elastic Net:", r2_elastic_net, "\n")

```

comparacion de los tres modelo 
Elastic Net tiene un R² de 0.979 y un RMSE de 38.98. Este modelo muestra un buen ajuste a los datos, con el 97.9% de la variabilidad en las calorías quemadas. La combinación de penalizaciones de Ridge y Lasso le permite manejar bien tanto la multicolinealidad como realizar una selección de variables. Aunque su MSE es de 1519.821, este valor se encuentra dentro de un rango razonable.

Ridge, por su parte, tiene un R² de 0.9676 y un RMSE de 48.42, lo que indica que aunque el modelo también tiene un buen ajuste, no es tan preciso como Elastic Net en términos de predicción.Su MSE es de 2344.048, es decir, más alto en comparación con los otros dos modelos.

Lasso es bastante similar al modelo Elastic Net, con un R² de 0.979 y un RMSE de 38.98. Al igual que Elastic Net, Lasso ha realizado una selección de variables, eliminando aquellas que no aportan significativamente a la predicción en nuestro caso Gender, Max_BPM, Workout_Type, Water_Intake, Experience_Level.

Tras comparar los tres modelos decidimos que para estimar las calorías que se queman, creomos que el modelo Elastic Net es una gran opción porque une las ventajas de Lasso y Ridge. Siendo capaz de manejar la multicolinealidad y también selecciona variables, lo cual es muy útil cuando hay muchas variables que están relacionadas. Además, Elastic Net es adaptable, ya que permite modificar el parámetro alpha, lo que le ayuda a ajustarse mejor a las particularidades del conjunto de datos y a equilibrar el sesgo con la varianza.

Como observamos en el modelo Elastic Net tenemos un lambda de 1.046946 que indica que el modelo ha encontrado un equilibrio adecuado entre la penalización y el ajuste a los datos. se ha mantenido el R^2 en 0.979 sin embargo hemos conseguido un MSE de 1519.821 lo que es bastante razonable. El RMSE de 38.98 lo que significa que nuestros datos se desplazan aproximadamente 38.98 de los valores reales que en comparacion con el anterior hemos conseguido bajar.


```{r}
# Crear una tabla comparativa 
comparativa_modelos <- data.frame(
  Modelo = c("Elastic Net", "Ridge", "Lasso", "Forward Selection", "Backward Selection"),
  R2 = c(0.979, 0.9676, 0.979, 0.979, 0.9792),
  RMSE = c(38.98, 48.42, 38.98, 39.12, 39.12),
  MSE = c(1519.82, 2344.048, 1519.82, 1524.98, 1524.98),
  Lambda = c(1.046946, NA, NA, NA, NA)
)

# Mostrar la tabla comparativa
print(comparativa_modelos)

```

Tras comparar los distintos modelos de regresión, observamos que Elastic Net y Lasso ofrecenla mayor efectividad con un R² de 0.979 y un RMSE de 38.98, lo que sugiere una alta capacidad para explicar la variabilidad en las calorías quemadas con un error relativamente bajo. Ridge, por otro lado, presenta un R² menor (0.9676) y un RMSE mayor (48.42), lo que indica que es menos preciso en sus predicciones. Los modelos de selección de variables (Forward, Backward y Stepwise) también tienen un buen ajuste (R² = 0.979), pero al depender de la selección manual de variables y pueden no manejar bien la multicolinealidad.

En conclusión, el modelo Elastic Net es la mejor opción, ya que combina las ventajas de Lasso (eliminación de variables irrelevantes) y Ridge (manejo de multicolinealidad), logrando un equilibrio óptimo entre ajuste y estabilidad. Su menor error y mayor precisión  lo que hace estimar las calorías quemadas de manera confiable.


Al analizar los distintos métodos vemos que las variables más eliminadas son  Max_BPM, Water_Intake, Fat_Percentage y Experience_Leve lo que indica que variables que no nos dan una  información relevante. Session_Duration, Avg_BPM, Gender y Age aparecen constantemente, lo que nos confirma su importancia en la predicción. En particular, Session_Duration y Avg_BPM destacan como los factores más determinantes, ya que el tiempo de entrenamiento y la intensidad del esfuerzo medido en BPM tienen una relación directa con la quema de calorías.



# 5. Modelo de regresión lineal multiple.

Viendo la selección de variables anterior, vamos a elegir las variables que se han seleccionado con el modelo forward y el modelo stepwise

Primero de todo vamos a ver el modelo forward, una vez visto R2, ahora vamos a hacer el análisis de los residuos y la prueba de homocedasticidad.

```{r}
# Miramos el modelo
summary(modelo_forward)

# Obtener los residuos
residuos <- resid(modelo_forward)
valores_ajustados <- fitted(modelo_forward)

# Graficar residuos vs valores ajustados
plot(valores_ajustados, residuos,
     main = "Residuos vs Valores Ajustados",
     xlab = "Valores Ajustados",
     ylab = "Residuos",
     pch = 19, col = "blue")
abline(h = 0, col = "red", lwd = 2)

# Graficar histograma de los residuos
hist(residuos,
     main = "Histograma de Residuos",
     xlab = "Residuos",
     col = "lightblue", border = "black")

# Graficar QQ-plot de los residuos
qqnorm(residuos, main = "QQ-Plot de los Residuos")
qqline(residuos, col = "red", lwd = 2) 

shapiro_test <- shapiro.test(residuos)
cat("Prueba de Shapiro-Wilk para normalidad de los residuos:\n")
print(shapiro_test)
```

Ahora vamos a hacer la prueba de homocedasticidad.

```{r}
# Realizar la prueba de Breusch-Pagan para homocedasticidad
bptest_result <- bptest(modelo_forward)
cat("\nPrueba de Breusch-Pagan para homocedasticidad:\n")
print(bptest_result)
```

Como vemos, tenemos un p-valor que es por debajo de 0.05, por lo que tenemos un modelo que nos sugiere heterocedasticidad.

Ahora, vamos a ver el modelo que sale con el modelo hecho con stepwise

```{r}
# Miramos el modelo
summary(modelo_stepwise)

# Obtener los residuos
residuos <- resid(modelo_stepwise)
valores_ajustados <- fitted(modelo_stepwise)

# Graficar residuos vs valores ajustados
plot(valores_ajustados, residuos,
     main = "Residuos vs Valores Ajustados",
     xlab = "Valores Ajustados",
     ylab = "Residuos",
     pch = 19, col = "blue")
abline(h = 0, col = "red", lwd = 2)

# Graficar histograma de los residuos
hist(residuos,
     main = "Histograma de Residuos",
     xlab = "Residuos",
     col = "lightblue", border = "black")

# Graficar QQ-plot de los residuos
qqnorm(residuos, main = "QQ-Plot de los Residuos")
qqline(residuos, col = "red", lwd = 2) 

shapiro_test <- shapiro.test(residuos)
cat("Prueba de Shapiro-Wilk para normalidad de los residuos:\n")
print(shapiro_test)
```
```{r}
# Realizar la prueba de Breusch-Pagan para homocedasticidad
bptest_result <- bptest(modelo_stepwise)
cat("\nPrueba de Breusch-Pagan para homocedasticidad:\n")
print(bptest_result)
```
Al igual que el otro, vemos que tenemos un p-valor que es por debajo de 0.05, por lo que el modelo nos sugiere heterocedasticidad.

# 6. Modelos no lienales y transformación de variables.

Una vez vistos nuestros modelos de lineales simple y multiple, vamos a ver que transformación podemos hacer a nuestra variable objetivo de tal forma que podamos tener una mejor regresión.

## 6.1 Modelo no lineal simple.

En nuestro modelo lineal simple, hemos observado que en el modelo lineal simple hay mucha variablidad entre nuestras variables, podemos ver como al ver hacer la prueba de homocedasticidad vemos que nuestros datos tienen heterocedasticidad, para ello vamos a relizar el cambio a ambas variables por se parado y vamos a ver cual es la que mejor se adapta y nos da una mejor resolución. Primero vamos a ver la transformación de box-cox para ver cual es la transformación de variables que mejor se adapta a nuestro modelo

```{r}
# Ajuste de un modelo lineal simple
modelo_bc <- lm(Calories_Burned ~ Session_Duration, train)

# Aplicación de la transformación de Box-Cox
boxcox(modelo_bc)
```

Viendo esto tenemos que el valor óptimo de lambda con un 95% de seguridad esta en torno al 0.5, dado que es distinto de 0, la mejor transformación de variables que podemos tener es el logaritmo de la variable Y, en nuestro caso son Calories_Burned. Antes de nada, vamos a ver como se ve gráficamente nuestra variable comparado con antes.

```{r}
train |> ggplot(aes(x = Session_Duration, y = log(Calories_Burned))) +
  geom_point(alpha = 0.5, color = "blue") +
  geom_smooth(method = "lm", color = "red") +
  labs(title = "Relación entre Duración del Entrenamiento y Calorías Quemadas",
       x = "Duración del Entrenamiento (horas)", y = "Calorías Quemadas") +
  theme_minimal()
```

A simple vista, podemos ver que gráficamente ha mejorado bastante la variabilidad de nuestros datos, a continuación, vamos a crear el modelo aplicando el logaritmo a nuestra variable objetivo.

```{r}
model_log <- lm(log(Calories_Burned) ~ Session_Duration, train)
summary(model_log)
```

viendo el modelo modificado, podemos ver como el Rcuadrado a aumentado un poco, hemos pasado de un 0.81 a un 0.82, ahora vamos a ver como se ven los residuos y vamos a hacer la prueba de homocedasticidad para ver si ha mejorado. Además de esto, podemos ver que el p-valor del intercepto ha mejorado significativamente, al principio su tenia un p-valor de 0.7 y ahora tenemos un p-valor menor a 2e-16.

```{r}
# Obtener los residuos
residuos <- resid(model_log)
valores_ajustados <- fitted(model_log)

# Graficar residuos vs valores ajustados
plot(valores_ajustados, residuos,
     main = "Residuos vs Valores Ajustados",
     xlab = "Valores Ajustados",
     ylab = "Residuos",
     pch = 19, col = "blue")
abline(h = 0, col = "red", lwd = 2)

# Graficar histograma de los residuos
hist(residuos,
     main = "Histograma de Residuos",
     xlab = "Residuos",
     col = "lightblue", border = "black")

# Graficar QQ-plot de los residuos
qqnorm(residuos, main = "QQ-Plot de los Residuos")
qqline(residuos, col = "red", lwd = 2) 

shapiro_test <- shapiro.test(residuos)
cat("Prueba de Shapiro-Wilk para normalidad de los residuos:\n")
print(shapiro_test)
```

Viendo esto se ve que los residuos no llegan a ser del todo normales, sin embargo, su variabilidad no está tán variada, ahora vamos a hacer la prueba de homocedaticidad.

```{r}
# Realizar la prueba de Breusch-Pagan para homocedasticidad
bptest_result <- bptest(model_log)
cat("\nPrueba de Breusch-Pagan para homocedasticidad:\n")
print(bptest_result)
```
Como podemos ver el p-valor a aumentado significativamente respecto al modelo original, pasando de un p-vamor muy pequeño a 0.8456, por lo que podemos decir que despues de esta transformación nuestras datos cumplen homocedasticidad diciendonos que la varianza de nuestros residuos presentan una variable constante.

## 6.2 Modelo no lineal multiple

Dado que hemos seleccionado uno de los modelos multiples, ahora vamos a ajustar los 
