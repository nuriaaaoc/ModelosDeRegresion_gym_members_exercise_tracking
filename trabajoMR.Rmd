---
title: "gym_members"
author: "Nuria Oviedo"
date: "2025-02-06"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Introducción

El conjunto de datos contiene un análisis de patrines de actividad física y rendimiento en distintos niveles de experiencia en gimnasios.

Estos datos se han extraido de [kaggle](https://www.kaggle.com/datasets/valakhorasani/gym-members-exercise-dataset). Segun la propia descripción de los datos,este conjunto de datos nos proporciona una descripción detallada de las turinad de ejercicio, los atributos físicos y las métricas de aptitud física de los miembros de gimnasios. En temas de salud es muy importante llevar un monitoreo de las cosas que hay que hacer para estar bien físicamente. El objetivo de este sistema es poder buscar patrones y evidencias de lo que tiene que hacer una persona para estar bien fisica y mentalmente. Este conjunto de dato nos da información sobre datos demográficos y niveles de experiencia, lo que permite un análisis integral de los patrones de aptitud física, la progresión de los atletas y las tendencias de salud. Además de esto no 

Según la descripción oficial de los datos, las variables que conforman el conjunto de datos son:

* Edad: Edad del miembro del gimnasio.
* Género: Género del miembro del gimnasio (masculino o femenino).
* Peso (kg): Peso del miembro en kilogramos.
* Altura (m): Altura del miembro en metros.
* Max_BPM: Frecuencia cardíaca máxima (pulsaciones por minuto) durante las sesiones de entrenamiento.
* Avg_BPM: Frecuencia cardíaca promedio durante las sesiones de entrenamiento.
* Resting_BPM: Frecuencia cardíaca en reposo antes del entrenamiento.
* Session_Duration (horas): Duración de cada sesión de entrenamiento en horas.
* Calorías_Quemadas: Total de calorías quemadas durante cada sesión.
* Workout_Type: Tipo de entrenamiento realizado (por ejemplo, Cardio, Fuerza, Yoga, HIIT).
* Fat_Percentage: Porcentaje de grasa corporal del miembro.
* Consumo_de_agua (litros): Ingesta diaria de agua durante los entrenamientos.
* Frecuencia_de_entrenamiento (días/semana): Número de sesiones de entrenamiento por semana.
* Nivel_Experiencia: Nivel de experiencia, desde principiante (1) hasta experto (3).
* IMC: Índice de Masa Corporal, calculado a partir de la altura y el peso.

Dado que es un problema de regresión, la variable objetivo (Cantidad de calorias quemadas durante la sesión de entrenamiento) es continua.


# Cargar paquetes necesarios

```{r}

library(ggplot2)
library(car) # pruebas de diagnóstico
library(lmtest) # prueba de homocedasticidad
library(dplyr) # manipulación de datos
library(GGally) # visualización avanzada
library(HistData) # datos históricos de Galton
library(gridExtra) # organizar múltiples gráficos
library(caret)
```


# Data undestandig

## Cargamos los datos.
```{r}
datos <- read.csv("gym_members_exercise_tracking.csv")
```
```{r include=FALSE}
datos <- datos %>% 
  rename(Weight = Weight..kg., 
         Height = Height..m., 
         Session_Duration = Session_Duration..hours., 
         Water_Intake = Water_Intake..liters., 
         Workout_Frequency = Workout_Frequency..days.week.)
```

## Tamaño del dataset.
```{r}
size <- dim(datos)
```

En estos datos podemos ver que tenemos un total de `r size[1]` observaciones y `r size [2]` variables en este dataset.

## Variables.
```{r}
str(datos)
```

Al ver esto podemos ver que estos datos son en su mayoría de tipo numérico o entero, sin embargo, tenemos dos variables de tipo cadena de caracteres (`char`), `Gender` y `Workout_Type`.

## Valores faltantes.
```{r}
sum(is.na(datos))
```

Vemos que no tenemos ningun datos faltante o missing entre nuestros datos.

## Primer vistazo a los datos.
```{r}
head(datos, 5)
```
Realizamos la partición de nuestros datos.

```{r}
# Ponemos una semilla para que la partición sea siempre la misma
set.seed(1)

# Buscamos los indices para la parte de train y de test y val
indices_train <- createDataPartition(datos$Calories_Burned, p = 0.7, list = FALSE)

# Creamos la variable train y test_val
train <- datos[indices_train, ]
test_val <- datos[-indices_train, ]

# Buscamos los indices para test
indices_test <- createDataPartition(test_val$Calories_Burned, p = 0.5, list = FALSE)

# Creamos la variabe test y val
test <- test_val[indices_test, ]
val <- test_val[-indices_test, ]
```

Miramos la información de nuestros datos de entrenamiento

```{r}
dim(train)
head(train)
str(train)
```

# EDA

Antes de nada vamos a ver información de nuestra variable objetivo importante
```{r}
summary(train$Calories_Burned)
```
Con esto nos da una idea de la cantidad de calorias que las personas pueden quemar, vemos como la media es casi 900 kcalorias y vemos tambien que el mínimo es de unas 300 kcal y el máximo es de 1700 kcal. 

Vamos a ver la forma de nuestra variable objetivo gráficamente.
```{r}
train |> ggplot(mapping = aes(x = Calories_Burned)) +
  geom_histogram()
```

Viendo este histograma se puede ver como las calorias quemadas se acerca a una distribución normal, viendo los datos de antes, se ve que este histograma si que tiene sentido. 

# Modelización estadística.
Nuestro problema para analizar es ver si hay alguna relación positiva entre las calorias que quema una persona por duración del entrenamineto, con esto buscamos como objetivo determinar si cuanto más tiempo una persona entrene, más kcalorias quema durante el entrenamiento. 

Las variables que se involucran seria el tiempo de duración de las sesiones de entrenamiento (variable explicativa) y la cantidad de calorias que quema una persona (variable respuesta).

Miramos los datos de la variable explicativa

```{r}
summary(train$Session_Duration)
```

Podemos ver que las personas entrenan una media de 1.256 horas, lo que hace 1 hora y 15 minutos, además podemos ver que dentro de los datos registrados, el mínimo de horas que se ha almacenado es de 0.5 horas y el máximo es de 2 horas.

Observamos los datos de esas dos variables.

```{r}
problema <- train |> select(Session_Duration, Calories_Burned)
head(problema, 5)
```

Viendo esta cabecera, se puede ver a simple vista que si que puede haber una realción entre la duración de el entrenamiento con las calorias que se queman, para verlo más claro, representamos ambas variables graficamente.

```{r}
train |>
  ggplot(mapping = aes(x = Calories_Burned, y = Session_Duration)) +
  geom_point()
```

Dado que tenemos una relación positiva entre estas dos variables, voy a proponer un modelso para relacionar estas dos variables., buscamos mediante el método de mínimos cuadrados hallar los valores de $\beta_0$ y $\beta_1$ para poder llegar a un modelo con la forma: $\text{Calorias} = \beta_0 + \beta_1 \text{(Tiempo de entrenamient0)} + \epsilon$.

```{r}
# Creamos el modelo lineal y lo analizamos
model <- lm(Calories_Burned ~ Session_Duration, data = train)
summary(model)
```

Ahora vamos a ver el modelo gráficamente.

```{r}
train |> 
  ggplot(mapping = aes(x = Calories_Burned, y = Session_Duration)) +
  geom_point() +
  geom_smooth(method = "lm", col = "red") +
  labs(title = "Relación entre calorias quemadas y la duración de la sesion.",
       x = "Calorias quemadas.",
       y = "Duración de la sesion.") +
  annotate("text", x = 500, y = 2.0, label = paste("y =", round(coef(model)[1], 2), "+", round(coef(model)[2], 2), "x"), color = "red")
```

La linea nos muestra una relación alcista segun las calorias quemadas y el tiempo de entrenamiento. Que el valor de $\beta_0$ sea menor a 0 no nos importa mucho, debido a que el mínimo es 0.5 (media hora) por lo que nunca va a ser negarivo ya que $\beta_1$ es 721.79 

# Correlación

Vamos a calcular y entender la correlación entre las variables de nuestro estudio.

## Covarianza
```{r}
calorias <- train$Calories_Burned
sesion <- train$Session_Duration

covarianza <- round(cov(calorias, sesion), 3)

print(paste("La covarianza entre la calorias quemadas por la sesion de entrenamiento es: ", covarianza))
```

Con esta covarianza podemos observar que ambas variables aumentan juntas, además de que no es cercana a 0 por lo que entre estas variables hay una relación lineal entre las variables.

## Coeficiente de correlación de lineal.
Calculamos y mostramos el coeficiente de correlación de Pearson entre la duración de las sesiones de ejercicio y las calorías quemadas.

```{r}
correlacion_pearson <- cor(train$Session_Duration, train$Calories_Burned, use = "complete.obs")
cat("El coeficiente de correlación de Pearson entre la duración de la sesión y las calorías quemadas es:", round(correlacion_pearson, 8), "\n")
```

La correlación de Pearson nos confirma lo que habiamos visto calculando la covarianza, como es cercano a 1, existe una relación lineal fuerte entre las variables y como es positivo, las variables aumentan a la par.
# tabla ANOVA
tras realizar el analísis de la tabla de varianza (ANOVA) podemos concluir que los factores más influyentes son 
la duración de la sesión, el average BPM, el género y el año. Luego encontramos factores influyentes pero en menor medida como el BMI y la altura. El resto de factores no son influyentes en la quema de calorías
```{r}
# Ajustar el modelo de regresión lineal
modelo <- lm(Calories_Burned ~ Age + Gender  + Height+ Weight + Max_BPM + Avg_BPM + Resting_BPM + Session_Duration+ Calories_Burned + Workout_Type + Fat_Percentage + Water_Intake + Workout_Frequency + Experience_Level + BMI , data = train)

# Obtener la tabla ANOVA
tabla_anova <- anova(modelo)
cat("Tabla ANOVA:\n")
#mostrar tabla anova
print(tabla_anova)
```


# Análisis de Residuos

Realizamos el análisis de residuos para evaluar el modelo ajustado.

### 1. Residuos vs Valores Ajustados

```{r}
# Obtener los residuos
residuos <- resid(model)
valores_ajustados <- fitted(model)

# Graficar residuos vs valores ajustados
plot(valores_ajustados, residuos,
     main = "Residuos vs Valores Ajustados",
     xlab = "Valores Ajustados",
     ylab = "Residuos",
     pch = 19, col = "blue")
abline(h = 0, col = "red", lwd = 2)

```
Podemos observar que los residuos se distribuyen de manera aleatoria alrededor del eje, sin mostrar patrones claros, poor lo que el supuesto de linealidad se cumple. 



### 2. Histograma de los Residuos
```{r}
# Graficar histograma de los residuos
hist(residuos,
     main = "Histograma de Residuos",
     xlab = "Residuos",
     col = "lightblue", border = "black")

```
Podemos observar que nuestra distribución se acerca a una distribucion noral con un ligero desplazamiento a la izquierda. 



### 3. QQ-Plot de los Residuos


```{r}

# Graficar QQ-plot de los residuos
qqnorm(residuos, main = "QQ-Plot de los Residuos")
qqline(residuos, col = "red", lwd = 2) 

```
podemos observar que los puntos se alinean con la linea roja diagonal, por lo que podemos deducir que siguen una distribucion normal y concuerda con lo esperado.



### 4. Prueba de Normalidad de los Residuos (Shapiro-Wilk)

```{r}
# Realizar la prueba de Shapiro-Wilk para normalidad de los residuos

shapiro_test <- shapiro.test(residuos)
cat("Prueba de Shapiro-Wilk para normalidad de los residuos:\n")
print(shapiro_test)

```
Observamos que el p-valor obtenido es menor que 0.05, por lo que rechazaríamos la Hipótesis nula.





# Diagnóstico del Modelo: Pruebas de Homocedasticidad y Leverage

### 1. Prueba de Homocedasticidad (Breusch-Pagan)

```{r}
# Realizar la prueba de Breusch-Pagan para homocedasticidad
bptest_result <- bptest(model)
cat("\nPrueba de Breusch-Pagan para homocedasticidad:\n")
print(bptest_result)

```
La prueba de Breusch-Pagan muestra un valor p muy pequeño (< 2.2e-16), lo que indica que hay heterocedasticidad en el modelo. Esto significa que los errores del modelo no tienen una varianza constante, lo que puede afectar la precisión de los resultados. En términos más simples, la relación entre las variables puede cambiar dependiendo de ciertos factores, como la experiencia en el gimnasio o características físicas de los usuarios. Para corregir esto, se pueden hacer algunos ajustes, como transformar los datos, usar otro tipo de regresión o aplicar correcciones estadísticas para mejorar la fiabilidad del análisis.


### 2. Análisis de Leverage 

Calculamos el leverage de las observaciones y graficamos las observaciones con leverage alto.

```{r}
# Calcular leverage
leverage <- hatvalues(model)

# Umbral para leverage alto
n <- nrow(train)
p <- length(coef(train))  # Número de parámetros (incluyendo el intercepto)
leverage_threshold <- 2 * p / n

# Identificar observaciones con leverage alto
leverage_high <- which(leverage > leverage_threshold)

cat("\nUmbral para leverage alto:", leverage_threshold, "\n")
cat("\nObservaciones con leverage alto (si las hay):\n")
print(leverage_high)

# Gráfico de leverage
grafico_leverage <- ggplot(data.frame(leverage), aes(x = seq_along(leverage), y = leverage)) +
  geom_point(color = "blue") +
  geom_hline(yintercept = leverage_threshold, col = "red", lwd = 2, lty = 2) +
  labs(title = "Leverage de las Observaciones", x = "Índice de Observación", y = "Leverage")

# Mostrar gráfico
grafico_leverage
```

El gráfico de leverage muestra la influencia de cada observación en los coeficientes del modelo. Observaciones con leverage alto (por encima del umbral) tienen un gran efecto en el ajuste del modelo.
El gráfico de leverage muestra que la mayoría de las observaciones tienen un leverage bajo, lo que indica que no influyen demasiado en el ajuste del modelo. Sin embargo, hay una dispersión uniforme de puntos a ambos lados de la línea roja discontinua en niveles más altos de leverage. Esto sugiere que algunas observaciones tienen un mayor impacto en los coeficientes del modelo y podrían ser casos atípicos o influyentes. Es importante analizar estos puntos para determinar si afectan negativamente la estabilidad del modelo y, si es necesario, considerar ajustes o métodos robustos.


### 3. Análisis de la Distancia de Cook

 mide la influencia de cada observación sobre los coeficientes del modelo.

```{r}
# Calcular Distancia de Cook
cooks_distance <- cooks.distance(model)

# Gráfico de Distancia de Cook
grafico_cooks_distance <- ggplot(data.frame(cooks_distance), aes(x = seq_along(cooks_distance), y = cooks_distance)) +
  geom_point(color = "blue") +
  geom_hline(yintercept = 4 / n, col = "red", lwd = 2, lty = 2) +
  labs(title = "Distancia de Cook", x = "Índice de Observación", y = "Distancia de Cook")

# Mostrar gráfico
grafico_cooks_distance

```

La distancia de Cook mide la influencia de cada observación sobre los coeficientes del modelo. Observaciones con una distancia de Cook alta (por encima del umbral) pueden ser altamente influyentes. En el gráfico, hay algunas observaciones con distancia de Cook alta, lo que indica que estas observaciones pueden estar afectando de manera desproporcionada el ajuste del modelo
Podemos observar que la mayoría de las observaciones tienen una influencia baja en el modelo, ya que están acumuladas en la parte inferior, cerca de la línea roja. Sin embargo, hay algunas observaciones con una distancia de Cook alta, lo que indica que pueden estar afectando de manera significativa el ajuste del modelo. Estos puntos atípicos podrían estar influyendo de manera desproporcionada en los coeficientes, por lo que sería recomendable revisarlos para determinar si representan datos válidos o si es necesario aplicar ajustes para mejorar la estabilidad del modelo.

## Análisis de DFFITS

mide el cambio en los valores ajustados cuando se omite una observación.

```{r}
# Calcular DFFITS
dffits_values <- dffits(model)

# Gráfico de DFFITS
grafico_dffits <- ggplot(data.frame(dffits_values), aes(x = seq_along(dffits_values), y = dffits_values)) +
  geom_point(color = "green") +
  geom_hline(yintercept = c(2 * sqrt(length(coef(model)) / n)), col = "red", lwd = 2, lty = 2) +
  labs(title = "DFFITS", x = "Índice de Observación", y = "DFFITS")

# Mostrar gráfico
grafico_dffits

```

El gráfico de DFFITS muestra que la mayoría de las observaciones tienen poca influencia en el modelo, ya que están acumuladas alrededor de cero y dentro del rango de ±0.1, sin sobrepasar la línea roja. Sin embargo, hay algunas observaciones que superan este umbral, lo que indica que pueden estar afectando significativamente los valores ajustados. Estas observaciones deberían revisarse para determinar si representan datos válidos o si están distorsionando el modelo, ya que podrían influir en la precisión de las predicciones


## Análisis de DFBETAS

nos indican la influencia de cada observación sobre cada coeficiente de la regresión.


```{r}
# Calcular DFBETAS# Calcular DFBETAS
dfbetas_values <- dfbetas(model)

# Convertir dfbetas_values a un data.frame para poder usarlo en ggplot
dfbetas_df <- as.data.frame(dfbetas_values)

# Graficar DFBETAS para el coeficiente de la pendiente (segunda columna si existe)
grafico_dfbetas <- ggplot(dfbetas_df, aes(x = seq_along(dfbetas_df[,2]), y = dfbetas_df[,2])) + # Usamos el coeficiente de la pendiente
  geom_point(color = "purple") +
  geom_hline(yintercept = 2 / sqrt(n), col = "red", lwd = 2, lty = 2) +
  labs(title = "DFBETAS para el Coeficiente de la Pendiente", x = "Índice de Observación", y = "DFBETAS")

# Mostrar gráfico
grafico_dfbetas


```
El gráfico de DFBETAS muestra que la mayoría de las observaciones tienen poca influencia en los coeficientes del modelo, ya que están acumuladas alrededor de cero y dentro del rango de ±0.1, sin sobrepasar la línea roja. Sin embargo, algunas observaciones superan este umbral, lo que indica que pueden estar afectando de manera significativa los coeficientes de regresión. Es importante revisar estos puntos para determinar si están influyendo de manera desproporcionada en el modelo y, si es necesario, considerar ajustes para mejorar su estabilidad.


#MODELO REGRESION LINEAL MÚLTIPLE

```{r}

# Ajustar modelo de regresión lineal múltiple
modelo <- lm(Calories_Burned ~ Age + Gender + Weight + Height + Max_BPM + 
             Avg_BPM + Resting_BPM + Session_Duration + BMI + 
             Workout_Type + Fat_Percentage + Water_Intake + 
             Workout_Frequency + Experience_Level, data = train)

# Resumen del modelo
summary(modelo)

```
El modelo de regresión lineal múltiple presenta un **ajuste muy fuerte** con un \( R^2 \) de **0.9851**, lo que indica que el 98.51% de la variabilidad en el **BMI** puede explicarse por las variables independientes incluidas. Variables como **peso (p < 0.001)**, **altura (p < 0.001)**, **género (p < 0.001)**, **edad (p = 0.00215)** y **calorías quemadas (p = 0.01446)** son estadísticamente significativas, lo que sugiere que tienen un impacto importante en el BMI. En contraste, variables como **frecuencia de entrenamiento, nivel de experiencia y consumo de agua** no muestran una relación estadísticamente significativa con el BMI. Además, los residuos parecen estar bien distribuidos, lo que respalda la validez del modelo. Sin embargo, la relación negativa con la **duración de la sesión de ejercicio** y la no significancia de la **frecuencia de entrenamiento** pueden indicar la necesidad de revisar la influencia de estos factores en la predicción del BMI.


###  Interpretación de los Resultados

Los coeficientes estimados indican la relación entre cada variable independiente y el BMI:

Variables con valores p < 0.05 tienen un impacto significativo.
R² y R² ajustado indican cuánto del BMI puede explicarse por el modelo.

```{r}
# Extraer coeficientes y p-valores
coeficientes <- summary(modelo)$coefficients
coeficientes

```
gresión lineal múltiple indican que las variables como el peso, altura, género, edad y calorías quemadas tienen un impacto significativo sobre el BMI, lo que sugiere que estas son las variables más relevantes para predecir el índice de masa corporal. En cambio, otras variables como el nivel de experiencia, frecuencia de entrenamiento, porcentaje de grasa corporal y tipo de ejercicio no muestran una relación estadísticamente significativa en este contexto.

El R² alto (0.9851) y la baja desviación estándar de los residuos sugieren que el modelo tiene un buen ajuste, pero la falta de significancia de algunas variables podría implicar que estas tienen un efecto indirecto sobre el BMI o que se requieren transformaciones adicionales del modelo. Este análisis resalta la importancia de los factores físicos y metabólicos en la predicción del BMI, pero también sugiere que un análisis más detallado y ajustes en las variables podrían mejorar la precisión del modelo.


#Diagnóstico del Modelo

Analizamos los residuos y verificamos la validez de los supuestos del modelo.

```{r}
# Gráfico de residuos vs valores ajustados
ggplot(data = train, aes(x = fitted(modelo), y = residuals(modelo))) +
  geom_point() +
  geom_hline(yintercept = 0, col = "red") +
  labs(title = "Residuos vs Valores Ajustados", x = "Valores Ajustados", y = "Residuos")

# Histograma de residuos para evaluar normalidad
ggplot(data.frame(residuales = residuals(modelo)), aes(x = residuales)) +
  geom_histogram(bins = 20, fill = "blue", alpha = 0.7) +
  labs(title = "Distribución de los Residuos", x = "Residuos", y = "Frecuencia")
# Gráfico de residuos vs valores ajustados
ggplot(data = datos, aes(x = fitted(modelo), y = residuals(modelo))) +
  geom_point() +
  geom_hline(yintercept = 0, col = "red") +
  labs(title = "Residuos vs Valores Ajustados", x = "Valores Ajustados", y = "Residuos")

# Histograma de residuos para evaluar normalidad
ggplot(data.frame(residuales = residuals(modelo)), aes(x = residuales)) +
  geom_histogram(bins = 20, fill = "blue", alpha = 0.7) +
  labs(title = "Distribución de los Residuos", x = "Residuos", y = "Frecuencia")

```
El análisis de los residuos muestra que estos siguen una distribución aproximadamente normal, lo cual se confirma con el histograma que no presenta colas largas ni desplazamientos significativos. Esto sugiere que no hay grandes violaciones de los supuestos de normalidad, lo que respalda la validez del modelo. Además, el gráfico de residuos vs valores ajustados El gráfico de residuos vs valores ajustados muestra una forma que sugiere una ligera tendencia en los residuos, especialmente cerca de los valores de x=25 y y=0 (línea roja). Aunque la mayoría de los residuos están dispersos de manera aleatoria alrededor de la línea cero, esta leve concentración en una zona particular podría indicar la presencia de heterocedasticidad, es decir, que la varianza de los residuos no es constante en todo el rango de valores ajustados. Este patrón podría sugerir que el modelo no captura completamente ciertos aspectos de los datos en esos puntos específicos. A pesar de esto, la distribución general de los residuos es adecuada, lo que indica que el modelo es relativamente bueno, aunque se podrían considerar transformaciones o la inclusión de nuevas variables para mejorar su precisión en las áreas donde se observa esta ligera tendencia. 
